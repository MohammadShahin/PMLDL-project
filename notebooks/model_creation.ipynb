{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdff083e-cce0-423c-92bf-ed174180b283",
   "metadata": {},
   "source": [
    "First we import all the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7d948b-364d-4ae1-a78f-5a59f387771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahmo\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from IPython.display import Video\n",
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "import argparse\n",
    "import logging\n",
    "from sys import exit\n",
    "import shutil\n",
    "\n",
    "from timm.models import create_model, apply_test_time_pool\n",
    "from timm.data import ImageDataset, create_loader, resolve_data_config\n",
    "from timm.utils import AverageMeter, setup_default_logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7e363d-c855-47f8-a7fc-676923ac535f",
   "metadata": {},
   "source": [
    "We do some setting up here. First we define `debug`. If `debug` is set then that means that we do not actually want to train the model we're just checking if everything is working. That means small number of epochs and small amount of videos to train on.\n",
    "\n",
    "We will try different error tolrances for each type of event and tune it as a hyper parameter. We basically instead of giving the model a second where an event happens we give it a range of [event_timestamp - err_tol, event_timestamp + err_tol] and train it on that. \n",
    "\n",
    "Since the dataset is very small, we dine the train/validation split manually. Once everything is ready we will try different combinations manually and keep the one that gives the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e4bffc-4522-40e8-bf7e-cba4ac43c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "if debug:\n",
    "    epochs = 3\n",
    "else:\n",
    "    epochs = 20\n",
    "\n",
    "err_tol = {\n",
    "    'challenge': [ 0.30, 0.40, 0.50, 0.60, 0.70 ],\n",
    "    'play': [ 0.15, 0.20, 0.25, 0.30, 0.35 ],\n",
    "    'throwin': [ 0.15, 0.20, 0.25, 0.30, 0.35 ]\n",
    "}\n",
    "video_id_split = {\n",
    "    'val':[\n",
    "         '3c993bd2_0',\n",
    "         '3c993bd2_1',\n",
    "    ],\n",
    "    'train':[\n",
    "         '1606b0e6_0',\n",
    "         '1606b0e6_1',\n",
    "         '35bd9041_0',\n",
    "         '35bd9041_1',\n",
    "         '407c5a9e_1',\n",
    "         '4ffd5986_0',\n",
    "         '9a97dae4_1',\n",
    "         'cfbe2e94_0',\n",
    "         'cfbe2e94_1',\n",
    "         'ecf251d4_0',\n",
    "    ]\n",
    "}\n",
    "event_names = ['challenge', 'throwin', 'play']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd2f11f-3362-4778-bd17-3d71e2a74156",
   "metadata": {},
   "source": [
    "We then load the data and remove every value of the form [id, timestamp, event_type, attr] (except for types `start` and `end`) and add two values in its place [id, timestamp - err_tol, start_event_type, attr] and [id, timestamp + err_tol, end_event_type, attr]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61fed164-c5ef-404e-8ba7-adab69342d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>time</th>\n",
       "      <th>event</th>\n",
       "      <th>event_attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>200.265822</td>\n",
       "      <td>start</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>start_challenge</td>\n",
       "      <td>['ball_action_forced']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>201.300000</td>\n",
       "      <td>end_challenge</td>\n",
       "      <td>['ball_action_forced']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>202.765822</td>\n",
       "      <td>end</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>210.124111</td>\n",
       "      <td>start</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11214</th>\n",
       "      <td>ecf251d4_0</td>\n",
       "      <td>3058.072895</td>\n",
       "      <td>end</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11215</th>\n",
       "      <td>ecf251d4_0</td>\n",
       "      <td>3068.280519</td>\n",
       "      <td>start</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>ecf251d4_0</td>\n",
       "      <td>3069.472000</td>\n",
       "      <td>start_throwin</td>\n",
       "      <td>['pass']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>ecf251d4_0</td>\n",
       "      <td>3069.622000</td>\n",
       "      <td>end_throwin</td>\n",
       "      <td>['pass']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11217</th>\n",
       "      <td>ecf251d4_0</td>\n",
       "      <td>3070.780519</td>\n",
       "      <td>end</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15600 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id         time            event        event_attributes\n",
       "0      1606b0e6_0   200.265822            start                     NaN\n",
       "0      1606b0e6_0   201.000000  start_challenge  ['ball_action_forced']\n",
       "1      1606b0e6_0   201.300000    end_challenge  ['ball_action_forced']\n",
       "2      1606b0e6_0   202.765822              end                     NaN\n",
       "3      1606b0e6_0   210.124111            start                     NaN\n",
       "...           ...          ...              ...                     ...\n",
       "11214  ecf251d4_0  3058.072895              end                     NaN\n",
       "11215  ecf251d4_0  3068.280519            start                     NaN\n",
       "8762   ecf251d4_0  3069.472000    start_throwin                ['pass']\n",
       "8763   ecf251d4_0  3069.622000      end_throwin                ['pass']\n",
       "11217  ecf251d4_0  3070.780519              end                     NaN\n",
       "\n",
       "[15600 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dfl-bundesliga-data-shootout/train.csv\")\n",
    "additional_events = []\n",
    "for arr in df.sort_values(['video_id','time','event','event_attributes']).values:\n",
    "    if arr[2] in err_tol:\n",
    "        tol = err_tol[arr[2]][0]/2\n",
    "        additional_events.append([arr[0], arr[1]-tol, 'start_'+arr[2], arr[3]])\n",
    "        additional_events.append([arr[0], arr[1]+tol, 'end_'+arr[2], arr[3]])\n",
    "df = pd.concat([df, pd.DataFrame(additional_events, columns=df.columns)])\n",
    "df = df[~df['event'].isin(event_names)]\n",
    "df = df.sort_values(['video_id', 'time'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70b5e93-8875-44f3-8231-6e0c5ab3c6d0",
   "metadata": {},
   "source": [
    "In the next cell we go over every video and split it into photos. We assign 4 different kinds of photos. If a certain frame falls between the start and end of a certain event then the photo of that frame is assigned to that type. If a certain frame doesn't fall in any event then we assign it to type `background` which means no event is happening in this frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c42da86d-d1e4-44f9-b577-5442e974af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_training_images(args):\n",
    "        video_id, split = args\n",
    "        video_path = f\"../dfl-bundesliga-data-shootout/train/{video_id}.mp4\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        time_interval = 1/fps\n",
    "\n",
    "        df_video = df[df.video_id == video_id]\n",
    "        if debug:\n",
    "            df_video = df_video.head(10)\n",
    "        print(split, video_id, df_video.shape)\n",
    "\n",
    "        arr = df_video[['time','event']].values\n",
    "        for idx in range(len(arr)-1):\n",
    "            crr_frame = int(math.ceil(arr[idx,0] * fps))\n",
    "            nxt_frame = int(math.ceil(arr[idx+1,0] * fps))\n",
    "            crr_event = arr[idx,1]\n",
    "\n",
    "            crr_event = crr_event\n",
    "            if crr_event == 'start':\n",
    "                crr_status = 'background'\n",
    "            elif crr_event == 'end':\n",
    "                # should use as background?\n",
    "                continue\n",
    "            else:\n",
    "                start_or_end, crr_status = crr_event.split('_', 1)\n",
    "                if start_or_end == 'end':\n",
    "                    crr_status = 'background'\n",
    "\n",
    "            result_dir = f\"../work/split_images/{split}/{crr_status}\"\n",
    "            if not os.path.exists(result_dir):\n",
    "                os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "            this_frame = crr_frame\n",
    "            while this_frame < nxt_frame:\n",
    "                frame_num = this_frame\n",
    "\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "                ret, frame = cap.read()\n",
    "                out_file = f'{result_dir}/{video_id}_{frame_num:06}.jpg'\n",
    "                cv2.imwrite(out_file, frame)\n",
    "\n",
    "                if crr_status == 'background':\n",
    "                    this_frame += 10\n",
    "                else:\n",
    "                    this_frame += 1\n",
    "\n",
    "#shutil.rmtree('../work/split_images')\n",
    "#for split in video_id_split:\n",
    "#    video_ids = video_id_split[split]\n",
    "#    for video_id in video_ids:            \n",
    "#        extract_training_images([video_id, split])\n",
    "#print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f77845-68fa-45b2-873a-259c4619d9b6",
   "metadata": {},
   "source": [
    "Training was causing memory problems, we used the following line to elevate the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d316ce5-db80-4037-bd14-d3a81f35a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3630949d-17a5-4c11-aa28-c7f94c162bf8",
   "metadata": {},
   "source": [
    "We use the pretrianed tf_efficientnet_b5_ap model from the timm library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad382223-8cdf-4a83-b0b3-7b67b2bd9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('./output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a7db7f-4f3d-4e13-94c1-c72a64bc365f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training with a single process on 1 GPUs.\n",
      "Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b5_ap-9e82fae8.pth)\n",
      "Model tf_efficientnet_b5_ap created, param count:28348980\n",
      "Data processing configuration for current model + dataset:\n",
      "\tinput_size: (3, 456, 456)\n",
      "\tinterpolation: bicubic\n",
      "\tmean: (0.5, 0.5, 0.5)\n",
      "\tstd: (0.5, 0.5, 0.5)\n",
      "\tcrop_pct: 0.934\n",
      "Using native Torch AMP. Training in mixed precision.\n",
      "Scheduled epochs: 30\n",
      "Train: 0 [   0/9556 (  0%)]  Loss: 1.672 (1.67)  Time: 31.455s,    0.13/s  (31.455s,    0.13/s)  LR: 1.000e-04  Data: 7.920 (7.920)\n",
      "Train: 0 [  50/9556 (  1%)]  Loss: 2.467 (2.04)  Time: 0.256s,   15.62/s  (0.882s,    4.54/s)  LR: 1.000e-04  Data: 0.002 (0.160)\n",
      "Train: 0 [ 100/9556 (  1%)]  Loss: 1.090 (1.83)  Time: 0.301s,   13.27/s  (0.582s,    6.88/s)  LR: 1.000e-04  Data: 0.002 (0.084)\n",
      "Train: 0 [ 150/9556 (  2%)]  Loss: 3.390 (1.72)  Time: 0.314s,   12.72/s  (0.481s,    8.32/s)  LR: 1.000e-04  Data: 0.003 (0.059)\n",
      "Train: 0 [ 200/9556 (  2%)]  Loss: 0.8373 (1.64)  Time: 0.266s,   15.04/s  (0.431s,    9.28/s)  LR: 1.000e-04  Data: 0.008 (0.046)\n",
      "Train: 0 [ 250/9556 (  3%)]  Loss: 1.681 (1.62)  Time: 0.255s,   15.68/s  (0.399s,   10.02/s)  LR: 1.000e-04  Data: 0.007 (0.038)\n",
      "Train: 0 [ 300/9556 (  3%)]  Loss: 1.447 (1.56)  Time: 0.263s,   15.20/s  (0.379s,   10.55/s)  LR: 1.000e-04  Data: 0.009 (0.033)\n",
      "Train: 0 [ 350/9556 (  4%)]  Loss: 1.537 (1.53)  Time: 0.352s,   11.35/s  (0.365s,   10.96/s)  LR: 1.000e-04  Data: 0.010 (0.029)\n",
      "Train: 0 [ 400/9556 (  4%)]  Loss: 0.7172 (1.50)  Time: 0.345s,   11.59/s  (0.354s,   11.31/s)  LR: 1.000e-04  Data: 0.009 (0.026)\n",
      "Train: 0 [ 450/9556 (  5%)]  Loss: 1.251 (1.49)  Time: 0.257s,   15.57/s  (0.345s,   11.60/s)  LR: 1.000e-04  Data: 0.002 (0.024)\n",
      "Train: 0 [ 500/9556 (  5%)]  Loss: 0.9180 (1.49)  Time: 0.305s,   13.10/s  (0.338s,   11.84/s)  LR: 1.000e-04  Data: 0.009 (0.023)\n",
      "Train: 0 [ 550/9556 (  6%)]  Loss: 0.7200 (1.48)  Time: 0.252s,   15.87/s  (0.332s,   12.03/s)  LR: 1.000e-04  Data: 0.009 (0.021)\n",
      "Train: 0 [ 600/9556 (  6%)]  Loss: 1.684 (1.46)  Time: 0.285s,   14.01/s  (0.328s,   12.21/s)  LR: 1.000e-04  Data: 0.002 (0.020)\n",
      "Train: 0 [ 650/9556 (  7%)]  Loss: 0.9801 (1.45)  Time: 0.303s,   13.18/s  (0.324s,   12.36/s)  LR: 1.000e-04  Data: 0.009 (0.019)\n",
      "Train: 0 [ 700/9556 (  7%)]  Loss: 0.8972 (1.45)  Time: 0.255s,   15.71/s  (0.320s,   12.49/s)  LR: 1.000e-04  Data: 0.008 (0.018)\n",
      "Train: 0 [ 750/9556 (  8%)]  Loss: 1.796 (1.45)  Time: 0.306s,   13.08/s  (0.317s,   12.60/s)  LR: 1.000e-04  Data: 0.009 (0.017)\n",
      "Train: 0 [ 800/9556 (  8%)]  Loss: 1.068 (1.44)  Time: 0.284s,   14.08/s  (0.315s,   12.71/s)  LR: 1.000e-04  Data: 0.002 (0.017)\n",
      "Train: 0 [ 850/9556 (  9%)]  Loss: 0.8826 (1.43)  Time: 0.256s,   15.63/s  (0.312s,   12.82/s)  LR: 1.000e-04  Data: 0.009 (0.016)\n",
      "Train: 0 [ 900/9556 (  9%)]  Loss: 1.523 (1.43)  Time: 0.256s,   15.64/s  (0.310s,   12.91/s)  LR: 1.000e-04  Data: 0.007 (0.016)\n",
      "Train: 0 [ 950/9556 ( 10%)]  Loss: 1.371 (1.43)  Time: 0.246s,   16.28/s  (0.308s,   12.99/s)  LR: 1.000e-04  Data: 0.001 (0.015)\n",
      "Train: 0 [1000/9556 ( 10%)]  Loss: 1.351 (1.42)  Time: 0.253s,   15.81/s  (0.307s,   13.05/s)  LR: 1.000e-04  Data: 0.004 (0.015)\n",
      "Train: 0 [1050/9556 ( 11%)]  Loss: 1.690 (1.42)  Time: 0.265s,   15.09/s  (0.305s,   13.12/s)  LR: 1.000e-04  Data: 0.009 (0.015)\n",
      "Train: 0 [1100/9556 ( 12%)]  Loss: 1.146 (1.41)  Time: 0.310s,   12.91/s  (0.304s,   13.17/s)  LR: 1.000e-04  Data: 0.003 (0.014)\n",
      "Train: 0 [1150/9556 ( 12%)]  Loss: 1.284 (1.41)  Time: 0.265s,   15.12/s  (0.302s,   13.22/s)  LR: 1.000e-04  Data: 0.010 (0.014)\n",
      "Train: 0 [1200/9556 ( 13%)]  Loss: 1.464 (1.41)  Time: 0.261s,   15.30/s  (0.301s,   13.27/s)  LR: 1.000e-04  Data: 0.007 (0.014)\n",
      "Train: 0 [1250/9556 ( 13%)]  Loss: 1.406 (1.40)  Time: 0.262s,   15.26/s  (0.301s,   13.31/s)  LR: 1.000e-04  Data: 0.009 (0.013)\n",
      "Train: 0 [1300/9556 ( 14%)]  Loss: 0.9201 (1.40)  Time: 0.265s,   15.08/s  (0.299s,   13.36/s)  LR: 1.000e-04  Data: 0.009 (0.013)\n",
      "Train: 0 [1350/9556 ( 14%)]  Loss: 1.565 (1.39)  Time: 0.376s,   10.65/s  (0.299s,   13.40/s)  LR: 1.000e-04  Data: 0.009 (0.013)\n",
      "Train: 0 [1400/9556 ( 15%)]  Loss: 1.399 (1.39)  Time: 0.302s,   13.24/s  (0.298s,   13.43/s)  LR: 1.000e-04  Data: 0.010 (0.013)\n",
      "Train: 0 [1450/9556 ( 15%)]  Loss: 1.832 (1.38)  Time: 0.259s,   15.42/s  (0.297s,   13.47/s)  LR: 1.000e-04  Data: 0.009 (0.013)\n",
      "Train: 0 [1500/9556 ( 16%)]  Loss: 1.190 (1.38)  Time: 0.296s,   13.52/s  (0.296s,   13.50/s)  LR: 1.000e-04  Data: 0.002 (0.012)\n",
      "Train: 0 [1550/9556 ( 16%)]  Loss: 0.8067 (1.37)  Time: 0.280s,   14.31/s  (0.296s,   13.53/s)  LR: 1.000e-04  Data: 0.008 (0.012)\n",
      "Train: 0 [1600/9556 ( 17%)]  Loss: 1.749 (1.37)  Time: 0.260s,   15.38/s  (0.295s,   13.56/s)  LR: 1.000e-04  Data: 0.004 (0.012)\n",
      "Train: 0 [1650/9556 ( 17%)]  Loss: 0.8551 (1.37)  Time: 0.259s,   15.45/s  (0.294s,   13.58/s)  LR: 1.000e-04  Data: 0.009 (0.012)\n",
      "Train: 0 [1700/9556 ( 18%)]  Loss: 1.069 (1.37)  Time: 0.257s,   15.55/s  (0.294s,   13.61/s)  LR: 1.000e-04  Data: 0.009 (0.012)\n",
      "Train: 0 [1750/9556 ( 18%)]  Loss: 0.8215 (1.36)  Time: 0.259s,   15.45/s  (0.293s,   13.63/s)  LR: 1.000e-04  Data: 0.011 (0.012)\n",
      "Train: 0 [1800/9556 ( 19%)]  Loss: 0.6715 (1.36)  Time: 0.258s,   15.49/s  (0.293s,   13.66/s)  LR: 1.000e-04  Data: 0.002 (0.012)\n",
      "Train: 0 [1850/9556 ( 19%)]  Loss: 1.479 (1.35)  Time: 0.303s,   13.22/s  (0.292s,   13.69/s)  LR: 1.000e-04  Data: 0.003 (0.011)\n",
      "Train: 0 [1900/9556 ( 20%)]  Loss: 0.8968 (1.36)  Time: 0.264s,   15.16/s  (0.292s,   13.71/s)  LR: 1.000e-04  Data: 0.008 (0.011)\n",
      "Train: 0 [1950/9556 ( 20%)]  Loss: 1.751 (1.35)  Time: 0.285s,   14.01/s  (0.291s,   13.73/s)  LR: 1.000e-04  Data: 0.007 (0.011)\n",
      "Train: 0 [2000/9556 ( 21%)]  Loss: 0.9601 (1.35)  Time: 0.264s,   15.13/s  (0.291s,   13.75/s)  LR: 1.000e-04  Data: 0.008 (0.011)\n",
      "Train: 0 [2050/9556 ( 21%)]  Loss: 1.124 (1.35)  Time: 0.309s,   12.94/s  (0.291s,   13.76/s)  LR: 1.000e-04  Data: 0.006 (0.011)\n",
      "Train: 0 [2100/9556 ( 22%)]  Loss: 1.614 (1.35)  Time: 0.257s,   15.56/s  (0.290s,   13.78/s)  LR: 1.000e-04  Data: 0.002 (0.011)\n",
      "Train: 0 [2150/9556 ( 23%)]  Loss: 1.676 (1.34)  Time: 0.301s,   13.27/s  (0.290s,   13.80/s)  LR: 1.000e-04  Data: 0.008 (0.011)\n",
      "Train: 0 [2200/9556 ( 23%)]  Loss: 1.136 (1.34)  Time: 0.256s,   15.60/s  (0.290s,   13.81/s)  LR: 1.000e-04  Data: 0.003 (0.010)\n",
      "Train: 0 [2250/9556 ( 24%)]  Loss: 0.9606 (1.34)  Time: 0.261s,   15.34/s  (0.289s,   13.83/s)  LR: 1.000e-04  Data: 0.010 (0.010)\n",
      "Train: 0 [2300/9556 ( 24%)]  Loss: 1.141 (1.34)  Time: 0.256s,   15.61/s  (0.289s,   13.85/s)  LR: 1.000e-04  Data: 0.010 (0.010)\n",
      "Train: 0 [2350/9556 ( 25%)]  Loss: 0.6696 (1.33)  Time: 0.267s,   14.97/s  (0.289s,   13.86/s)  LR: 1.000e-04  Data: 0.003 (0.010)\n",
      "Train: 0 [2400/9556 ( 25%)]  Loss: 0.9900 (1.33)  Time: 0.268s,   14.91/s  (0.288s,   13.88/s)  LR: 1.000e-04  Data: 0.002 (0.010)\n",
      "Train: 0 [2450/9556 ( 26%)]  Loss: 1.261 (1.33)  Time: 0.286s,   13.98/s  (0.288s,   13.89/s)  LR: 1.000e-04  Data: 0.002 (0.010)\n",
      "Train: 0 [2500/9556 ( 26%)]  Loss: 1.270 (1.33)  Time: 0.265s,   15.12/s  (0.288s,   13.90/s)  LR: 1.000e-04  Data: 0.010 (0.010)\n",
      "Train: 0 [2550/9556 ( 27%)]  Loss: 1.569 (1.32)  Time: 0.265s,   15.12/s  (0.288s,   13.91/s)  LR: 1.000e-04  Data: 0.010 (0.010)\n",
      "Train: 0 [2600/9556 ( 27%)]  Loss: 1.325 (1.32)  Time: 0.249s,   16.07/s  (0.287s,   13.93/s)  LR: 1.000e-04  Data: 0.002 (0.010)\n",
      "Train: 0 [2650/9556 ( 28%)]  Loss: 2.568 (1.32)  Time: 0.268s,   14.91/s  (0.287s,   13.94/s)  LR: 1.000e-04  Data: 0.008 (0.010)\n",
      "Train: 0 [2700/9556 ( 28%)]  Loss: 1.685 (1.31)  Time: 0.255s,   15.67/s  (0.287s,   13.95/s)  LR: 1.000e-04  Data: 0.005 (0.010)\n",
      "Train: 0 [2750/9556 ( 29%)]  Loss: 2.107 (1.31)  Time: 0.263s,   15.24/s  (0.287s,   13.96/s)  LR: 1.000e-04  Data: 0.010 (0.009)\n",
      "Train: 0 [2800/9556 ( 29%)]  Loss: 0.8102 (1.31)  Time: 0.287s,   13.94/s  (0.286s,   13.97/s)  LR: 1.000e-04  Data: 0.010 (0.009)\n",
      "Train: 0 [2850/9556 ( 30%)]  Loss: 0.7931 (1.31)  Time: 0.261s,   15.34/s  (0.286s,   13.98/s)  LR: 1.000e-04  Data: 0.008 (0.009)\n",
      "Train: 0 [2900/9556 ( 30%)]  Loss: 0.8527 (1.31)  Time: 0.260s,   15.41/s  (0.286s,   13.99/s)  LR: 1.000e-04  Data: 0.002 (0.009)\n",
      "Train: 0 [2950/9556 ( 31%)]  Loss: 1.391 (1.31)  Time: 0.254s,   15.76/s  (0.286s,   14.01/s)  LR: 1.000e-04  Data: 0.002 (0.009)\n",
      "Train: 0 [3000/9556 ( 31%)]  Loss: 1.089 (1.31)  Time: 0.258s,   15.53/s  (0.286s,   14.01/s)  LR: 1.000e-04  Data: 0.006 (0.009)\n",
      "Train: 0 [3050/9556 ( 32%)]  Loss: 1.265 (1.31)  Time: 0.260s,   15.39/s  (0.285s,   14.02/s)  LR: 1.000e-04  Data: 0.007 (0.009)\n",
      "Train: 0 [3100/9556 ( 32%)]  Loss: 0.6068 (1.30)  Time: 0.259s,   15.43/s  (0.285s,   14.02/s)  LR: 1.000e-04  Data: 0.004 (0.009)\n",
      "Train: 0 [3150/9556 ( 33%)]  Loss: 0.9796 (1.30)  Time: 0.362s,   11.05/s  (0.285s,   14.03/s)  LR: 1.000e-04  Data: 0.006 (0.009)\n",
      "Train: 0 [3200/9556 ( 33%)]  Loss: 0.9976 (1.30)  Time: 0.284s,   14.08/s  (0.285s,   14.04/s)  LR: 1.000e-04  Data: 0.001 (0.009)\n",
      "Train: 0 [3250/9556 ( 34%)]  Loss: 1.435 (1.30)  Time: 0.259s,   15.47/s  (0.285s,   14.03/s)  LR: 1.000e-04  Data: 0.002 (0.009)\n",
      "Train: 0 [3300/9556 ( 35%)]  Loss: 0.8613 (1.30)  Time: 0.353s,   11.33/s  (0.285s,   14.04/s)  LR: 1.000e-04  Data: 0.002 (0.009)\n",
      "Train: 0 [3350/9556 ( 35%)]  Loss: 0.6984 (1.30)  Time: 0.274s,   14.59/s  (0.285s,   14.04/s)  LR: 1.000e-04  Data: 0.003 (0.009)\n",
      "Train: 0 [3400/9556 ( 36%)]  Loss: 0.9026 (1.30)  Time: 0.300s,   13.31/s  (0.285s,   14.05/s)  LR: 1.000e-04  Data: 0.005 (0.009)\n",
      "Train: 0 [3450/9556 ( 36%)]  Loss: 1.468 (1.29)  Time: 0.259s,   15.45/s  (0.285s,   14.05/s)  LR: 1.000e-04  Data: 0.002 (0.009)\n",
      "Train: 0 [3500/9556 ( 37%)]  Loss: 0.6043 (1.29)  Time: 0.260s,   15.39/s  (0.285s,   14.06/s)  LR: 1.000e-04  Data: 0.002 (0.008)\n",
      "Train: 0 [3550/9556 ( 37%)]  Loss: 1.081 (1.29)  Time: 0.259s,   15.47/s  (0.284s,   14.06/s)  LR: 1.000e-04  Data: 0.003 (0.008)\n",
      "Train: 0 [3600/9556 ( 38%)]  Loss: 0.9653 (1.29)  Time: 0.259s,   15.47/s  (0.284s,   14.07/s)  LR: 1.000e-04  Data: 0.002 (0.008)\n",
      "Train: 0 [3650/9556 ( 38%)]  Loss: 1.179 (1.29)  Time: 0.282s,   14.17/s  (0.284s,   14.07/s)  LR: 1.000e-04  Data: 0.004 (0.008)\n",
      "Train: 0 [3700/9556 ( 39%)]  Loss: 1.451 (1.29)  Time: 0.259s,   15.45/s  (0.284s,   14.08/s)  LR: 1.000e-04  Data: 0.008 (0.008)\n",
      "Train: 0 [3750/9556 ( 39%)]  Loss: 0.6620 (1.28)  Time: 0.351s,   11.38/s  (0.284s,   14.09/s)  LR: 1.000e-04  Data: 0.003 (0.008)\n",
      "Train: 0 [3800/9556 ( 40%)]  Loss: 1.367 (1.28)  Time: 0.282s,   14.19/s  (0.284s,   14.09/s)  LR: 1.000e-04  Data: 0.006 (0.008)\n",
      "Train: 0 [3850/9556 ( 40%)]  Loss: 1.031 (1.28)  Time: 0.275s,   14.52/s  (0.284s,   14.10/s)  LR: 1.000e-04  Data: 0.006 (0.008)\n",
      "Train: 0 [3900/9556 ( 41%)]  Loss: 1.698 (1.28)  Time: 0.257s,   15.57/s  (0.284s,   14.10/s)  LR: 1.000e-04  Data: 0.004 (0.008)\n",
      "Train: 0 [3950/9556 ( 41%)]  Loss: 1.414 (1.28)  Time: 0.265s,   15.11/s  (0.284s,   14.10/s)  LR: 1.000e-04  Data: 0.007 (0.008)\n",
      "Train: 0 [4000/9556 ( 42%)]  Loss: 0.7893 (1.28)  Time: 0.283s,   14.13/s  (0.284s,   14.11/s)  LR: 1.000e-04  Data: 0.008 (0.008)\n",
      "Train: 0 [4050/9556 ( 42%)]  Loss: 1.062 (1.28)  Time: 0.258s,   15.52/s  (0.283s,   14.11/s)  LR: 1.000e-04  Data: 0.009 (0.008)\n",
      "Train: 0 [4100/9556 ( 43%)]  Loss: 0.9485 (1.27)  Time: 0.261s,   15.33/s  (0.283s,   14.12/s)  LR: 1.000e-04  Data: 0.002 (0.008)\n",
      "Train: 0 [4150/9556 ( 43%)]  Loss: 0.6683 (1.27)  Time: 0.259s,   15.43/s  (0.283s,   14.12/s)  LR: 1.000e-04  Data: 0.003 (0.008)\n",
      "Train: 0 [4200/9556 ( 44%)]  Loss: 0.6403 (1.27)  Time: 0.275s,   14.57/s  (0.283s,   14.12/s)  LR: 1.000e-04  Data: 0.004 (0.008)\n",
      "Train: 0 [4250/9556 ( 44%)]  Loss: 1.873 (1.27)  Time: 0.311s,   12.87/s  (0.283s,   14.12/s)  LR: 1.000e-04  Data: 0.010 (0.008)\n",
      "Train: 0 [4300/9556 ( 45%)]  Loss: 0.7891 (1.27)  Time: 0.252s,   15.89/s  (0.283s,   14.13/s)  LR: 1.000e-04  Data: 0.002 (0.008)\n",
      "Train: 0 [4350/9556 ( 46%)]  Loss: 1.088 (1.27)  Time: 0.260s,   15.39/s  (0.283s,   14.13/s)  LR: 1.000e-04  Data: 0.003 (0.008)\n",
      "Train: 0 [4400/9556 ( 46%)]  Loss: 0.8645 (1.27)  Time: 0.355s,   11.25/s  (0.283s,   14.13/s)  LR: 1.000e-04  Data: 0.009 (0.008)\n",
      "Train: 0 [4450/9556 ( 47%)]  Loss: 1.134 (1.27)  Time: 0.251s,   15.96/s  (0.283s,   14.13/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [4500/9556 ( 47%)]  Loss: 0.9551 (1.27)  Time: 0.261s,   15.35/s  (0.283s,   14.13/s)  LR: 1.000e-04  Data: 0.003 (0.007)\n",
      "Train: 0 [4550/9556 ( 48%)]  Loss: 0.8499 (1.27)  Time: 0.255s,   15.70/s  (0.283s,   14.14/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [4600/9556 ( 48%)]  Loss: 1.434 (1.27)  Time: 0.262s,   15.24/s  (0.283s,   14.14/s)  LR: 1.000e-04  Data: 0.004 (0.007)\n",
      "Train: 0 [4650/9556 ( 49%)]  Loss: 1.449 (1.26)  Time: 0.259s,   15.44/s  (0.283s,   14.14/s)  LR: 1.000e-04  Data: 0.004 (0.007)\n",
      "Train: 0 [4700/9556 ( 49%)]  Loss: 0.7593 (1.26)  Time: 0.267s,   14.96/s  (0.283s,   14.15/s)  LR: 1.000e-04  Data: 0.010 (0.007)\n",
      "Train: 0 [4750/9556 ( 50%)]  Loss: 1.983 (1.26)  Time: 0.353s,   11.32/s  (0.283s,   14.15/s)  LR: 1.000e-04  Data: 0.005 (0.007)\n",
      "Train: 0 [4800/9556 ( 50%)]  Loss: 2.033 (1.26)  Time: 0.259s,   15.46/s  (0.283s,   14.15/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [4850/9556 ( 51%)]  Loss: 1.239 (1.26)  Time: 0.349s,   11.46/s  (0.283s,   14.15/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [4900/9556 ( 51%)]  Loss: 1.343 (1.26)  Time: 0.278s,   14.39/s  (0.283s,   14.16/s)  LR: 1.000e-04  Data: 0.005 (0.007)\n",
      "Train: 0 [4950/9556 ( 52%)]  Loss: 1.169 (1.26)  Time: 0.280s,   14.27/s  (0.283s,   14.16/s)  LR: 1.000e-04  Data: 0.007 (0.007)\n",
      "Train: 0 [5000/9556 ( 52%)]  Loss: 2.058 (1.26)  Time: 0.260s,   15.38/s  (0.282s,   14.16/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [5050/9556 ( 53%)]  Loss: 1.838 (1.26)  Time: 0.260s,   15.37/s  (0.282s,   14.16/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [5100/9556 ( 53%)]  Loss: 1.781 (1.26)  Time: 0.260s,   15.36/s  (0.282s,   14.17/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [5150/9556 ( 54%)]  Loss: 0.8130 (1.26)  Time: 0.263s,   15.20/s  (0.282s,   14.17/s)  LR: 1.000e-04  Data: 0.008 (0.007)\n",
      "Train: 0 [5200/9556 ( 54%)]  Loss: 0.8433 (1.25)  Time: 0.255s,   15.67/s  (0.282s,   14.18/s)  LR: 1.000e-04  Data: 0.003 (0.007)\n",
      "Train: 0 [5250/9556 ( 55%)]  Loss: 0.8291 (1.25)  Time: 0.256s,   15.61/s  (0.282s,   14.18/s)  LR: 1.000e-04  Data: 0.004 (0.007)\n",
      "Train: 0 [5300/9556 ( 55%)]  Loss: 0.9203 (1.25)  Time: 0.260s,   15.37/s  (0.282s,   14.18/s)  LR: 1.000e-04  Data: 0.003 (0.007)\n",
      "Train: 0 [5350/9556 ( 56%)]  Loss: 1.563 (1.25)  Time: 0.388s,   10.30/s  (0.282s,   14.18/s)  LR: 1.000e-04  Data: 0.004 (0.007)\n",
      "Train: 0 [5400/9556 ( 57%)]  Loss: 1.545 (1.25)  Time: 0.298s,   13.42/s  (0.282s,   14.19/s)  LR: 1.000e-04  Data: 0.010 (0.007)\n",
      "Train: 0 [5450/9556 ( 57%)]  Loss: 1.087 (1.25)  Time: 0.257s,   15.55/s  (0.282s,   14.19/s)  LR: 1.000e-04  Data: 0.003 (0.007)\n",
      "Train: 0 [5500/9556 ( 58%)]  Loss: 1.288 (1.25)  Time: 0.254s,   15.78/s  (0.282s,   14.19/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [5550/9556 ( 58%)]  Loss: 2.181 (1.25)  Time: 0.270s,   14.80/s  (0.282s,   14.20/s)  LR: 1.000e-04  Data: 0.008 (0.007)\n",
      "Train: 0 [5600/9556 ( 59%)]  Loss: 2.171 (1.25)  Time: 0.348s,   11.48/s  (0.282s,   14.20/s)  LR: 1.000e-04  Data: 0.011 (0.007)\n",
      "Train: 0 [5650/9556 ( 59%)]  Loss: 0.8745 (1.25)  Time: 0.251s,   15.91/s  (0.282s,   14.20/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [5700/9556 ( 60%)]  Loss: 2.063 (1.24)  Time: 0.259s,   15.44/s  (0.282s,   14.21/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [5750/9556 ( 60%)]  Loss: 0.9174 (1.24)  Time: 0.259s,   15.44/s  (0.282s,   14.21/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [5800/9556 ( 61%)]  Loss: 1.267 (1.24)  Time: 0.316s,   12.66/s  (0.281s,   14.21/s)  LR: 1.000e-04  Data: 0.003 (0.007)\n",
      "Train: 0 [5850/9556 ( 61%)]  Loss: 1.143 (1.24)  Time: 0.276s,   14.52/s  (0.281s,   14.21/s)  LR: 1.000e-04  Data: 0.003 (0.007)\n",
      "Train: 0 [5900/9556 ( 62%)]  Loss: 0.8312 (1.24)  Time: 0.252s,   15.90/s  (0.281s,   14.21/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [5950/9556 ( 62%)]  Loss: 0.9914 (1.24)  Time: 0.311s,   12.85/s  (0.281s,   14.22/s)  LR: 1.000e-04  Data: 0.004 (0.007)\n",
      "Train: 0 [6000/9556 ( 63%)]  Loss: 0.7577 (1.24)  Time: 0.311s,   12.87/s  (0.281s,   14.22/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [6050/9556 ( 63%)]  Loss: 1.219 (1.24)  Time: 0.266s,   15.03/s  (0.281s,   14.22/s)  LR: 1.000e-04  Data: 0.009 (0.007)\n",
      "Train: 0 [6100/9556 ( 64%)]  Loss: 0.8641 (1.24)  Time: 0.259s,   15.44/s  (0.281s,   14.22/s)  LR: 1.000e-04  Data: 0.003 (0.007)\n",
      "Train: 0 [6150/9556 ( 64%)]  Loss: 1.026 (1.24)  Time: 0.310s,   12.89/s  (0.281s,   14.22/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [6200/9556 ( 65%)]  Loss: 1.071 (1.24)  Time: 0.259s,   15.47/s  (0.281s,   14.22/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [6250/9556 ( 65%)]  Loss: 1.561 (1.24)  Time: 0.255s,   15.67/s  (0.281s,   14.23/s)  LR: 1.000e-04  Data: 0.007 (0.007)\n",
      "Train: 0 [6300/9556 ( 66%)]  Loss: 0.8002 (1.24)  Time: 0.276s,   14.48/s  (0.281s,   14.23/s)  LR: 1.000e-04  Data: 0.007 (0.007)\n",
      "Train: 0 [6350/9556 ( 66%)]  Loss: 1.012 (1.24)  Time: 0.259s,   15.41/s  (0.281s,   14.23/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [6400/9556 ( 67%)]  Loss: 1.046 (1.23)  Time: 0.269s,   14.85/s  (0.281s,   14.23/s)  LR: 1.000e-04  Data: 0.008 (0.007)\n",
      "Train: 0 [6450/9556 ( 68%)]  Loss: 0.6499 (1.23)  Time: 0.268s,   14.92/s  (0.281s,   14.23/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [6500/9556 ( 68%)]  Loss: 0.6678 (1.23)  Time: 0.278s,   14.41/s  (0.281s,   14.23/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [6550/9556 ( 69%)]  Loss: 1.822 (1.23)  Time: 0.259s,   15.42/s  (0.281s,   14.23/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [6600/9556 ( 69%)]  Loss: 1.127 (1.23)  Time: 0.304s,   13.15/s  (0.281s,   14.23/s)  LR: 1.000e-04  Data: 0.002 (0.007)\n",
      "Train: 0 [6650/9556 ( 70%)]  Loss: 0.7831 (1.23)  Time: 0.313s,   12.80/s  (0.281s,   14.23/s)  LR: 1.000e-04  Data: 0.002 (0.006)\n",
      "Train: 0 [6700/9556 ( 70%)]  Loss: 0.9614 (1.23)  Time: 0.260s,   15.38/s  (0.281s,   14.24/s)  LR: 1.000e-04  Data: 0.005 (0.006)\n",
      "Train: 0 [6750/9556 ( 71%)]  Loss: 0.9331 (1.23)  Time: 0.267s,   14.97/s  (0.281s,   14.24/s)  LR: 1.000e-04  Data: 0.009 (0.006)\n",
      "Train: 0 [6800/9556 ( 71%)]  Loss: 1.357 (1.23)  Time: 0.273s,   14.66/s  (0.281s,   14.24/s)  LR: 1.000e-04  Data: 0.012 (0.006)\n",
      "Train: 0 [6850/9556 ( 72%)]  Loss: 1.150 (1.23)  Time: 0.276s,   14.52/s  (0.281s,   14.24/s)  LR: 1.000e-04  Data: 0.003 (0.006)\n",
      "Train: 0 [6900/9556 ( 72%)]  Loss: 0.8558 (1.23)  Time: 0.404s,    9.90/s  (0.281s,   14.24/s)  LR: 1.000e-04  Data: 0.005 (0.006)\n",
      "Train: 0 [6950/9556 ( 73%)]  Loss: 1.668 (1.23)  Time: 0.256s,   15.62/s  (0.281s,   14.24/s)  LR: 1.000e-04  Data: 0.002 (0.006)\n",
      "Train: 0 [7000/9556 ( 73%)]  Loss: 1.045 (1.23)  Time: 0.258s,   15.48/s  (0.281s,   14.24/s)  LR: 1.000e-04  Data: 0.008 (0.006)\n",
      "Train: 0 [7050/9556 ( 74%)]  Loss: 0.9930 (1.23)  Time: 0.278s,   14.38/s  (0.281s,   14.25/s)  LR: 1.000e-04  Data: 0.006 (0.006)\n",
      "Train: 0 [7100/9556 ( 74%)]  Loss: 1.501 (1.23)  Time: 0.260s,   15.41/s  (0.281s,   14.24/s)  LR: 1.000e-04  Data: 0.003 (0.006)\n",
      "Train: 0 [7150/9556 ( 75%)]  Loss: 1.063 (1.23)  Time: 0.278s,   14.37/s  (0.281s,   14.25/s)  LR: 1.000e-04  Data: 0.010 (0.006)\n",
      "Train: 0 [7200/9556 ( 75%)]  Loss: 1.356 (1.23)  Time: 0.257s,   15.57/s  (0.281s,   14.25/s)  LR: 1.000e-04  Data: 0.002 (0.006)\n",
      "Train: 0 [7250/9556 ( 76%)]  Loss: 1.408 (1.22)  Time: 0.258s,   15.51/s  (0.281s,   14.25/s)  LR: 1.000e-04  Data: 0.002 (0.006)\n",
      "Train: 0 [7300/9556 ( 76%)]  Loss: 0.6851 (1.22)  Time: 0.258s,   15.51/s  (0.281s,   14.25/s)  LR: 1.000e-04  Data: 0.002 (0.006)\n",
      "Train: 0 [7350/9556 ( 77%)]  Loss: 1.128 (1.22)  Time: 0.258s,   15.49/s  (0.281s,   14.25/s)  LR: 1.000e-04  Data: 0.003 (0.006)\n",
      "Train: 0 [7400/9556 ( 77%)]  Loss: 0.9185 (1.22)  Time: 0.256s,   15.60/s  (0.281s,   14.25/s)  LR: 1.000e-04  Data: 0.008 (0.006)\n",
      "Train: 0 [7450/9556 ( 78%)]  Loss: 0.7823 (1.22)  Time: 0.277s,   14.44/s  (0.281s,   14.25/s)  LR: 1.000e-04  Data: 0.002 (0.006)\n",
      "Train: 0 [7500/9556 ( 78%)]  Loss: 0.9338 (1.22)  Time: 0.284s,   14.09/s  (0.281s,   14.25/s)  LR: 1.000e-04  Data: 0.003 (0.006)\n",
      "Train: 0 [7550/9556 ( 79%)]  Loss: 0.8282 (1.22)  Time: 0.248s,   16.13/s  (0.281s,   14.25/s)  LR: 1.000e-04  Data: 0.002 (0.006)\n",
      "Train: 0 [7600/9556 ( 80%)]  Loss: 1.229 (1.22)  Time: 0.263s,   15.23/s  (0.281s,   14.25/s)  LR: 1.000e-04  Data: 0.009 (0.006)\n",
      "Train: 0 [7650/9556 ( 80%)]  Loss: 0.9546 (1.22)  Time: 0.286s,   14.01/s  (0.281s,   14.25/s)  LR: 1.000e-04  Data: 0.007 (0.006)\n",
      "Train: 0 [7700/9556 ( 81%)]  Loss: 1.373 (1.22)  Time: 0.254s,   15.75/s  (0.281s,   14.26/s)  LR: 1.000e-04  Data: 0.008 (0.006)\n",
      "Train: 0 [7750/9556 ( 81%)]  Loss: 0.7866 (1.22)  Time: 0.303s,   13.19/s  (0.281s,   14.26/s)  LR: 1.000e-04  Data: 0.010 (0.006)\n",
      "Train: 0 [7800/9556 ( 82%)]  Loss: 1.043 (1.22)  Time: 0.269s,   14.85/s  (0.281s,   14.26/s)  LR: 1.000e-04  Data: 0.009 (0.006)\n",
      "Train: 0 [7850/9556 ( 82%)]  Loss: 1.469 (1.22)  Time: 0.265s,   15.09/s  (0.280s,   14.26/s)  LR: 1.000e-04  Data: 0.009 (0.006)\n",
      "Train: 0 [7900/9556 ( 83%)]  Loss: 1.389 (1.21)  Time: 0.256s,   15.62/s  (0.280s,   14.26/s)  LR: 1.000e-04  Data: 0.009 (0.006)\n",
      "Train: 0 [7950/9556 ( 83%)]  Loss: 0.8570 (1.21)  Time: 0.261s,   15.35/s  (0.280s,   14.26/s)  LR: 1.000e-04  Data: 0.009 (0.006)\n",
      "Train: 0 [8000/9556 ( 84%)]  Loss: 1.641 (1.21)  Time: 0.251s,   15.92/s  (0.280s,   14.26/s)  LR: 1.000e-04  Data: 0.001 (0.006)\n",
      "Train: 0 [8050/9556 ( 84%)]  Loss: 0.6414 (1.21)  Time: 0.263s,   15.20/s  (0.280s,   14.27/s)  LR: 1.000e-04  Data: 0.011 (0.006)\n",
      "Train: 0 [8100/9556 ( 85%)]  Loss: 0.8655 (1.21)  Time: 0.271s,   14.78/s  (0.280s,   14.27/s)  LR: 1.000e-04  Data: 0.009 (0.006)\n",
      "Train: 0 [8150/9556 ( 85%)]  Loss: 1.400 (1.21)  Time: 0.256s,   15.61/s  (0.280s,   14.27/s)  LR: 1.000e-04  Data: 0.002 (0.006)\n",
      "Train: 0 [8200/9556 ( 86%)]  Loss: 0.9869 (1.21)  Time: 0.258s,   15.48/s  (0.280s,   14.27/s)  LR: 1.000e-04  Data: 0.010 (0.006)\n",
      "Train: 0 [8250/9556 ( 86%)]  Loss: 0.8623 (1.21)  Time: 0.305s,   13.11/s  (0.280s,   14.27/s)  LR: 1.000e-04  Data: 0.010 (0.006)\n",
      "Train: 0 [8300/9556 ( 87%)]  Loss: 1.759 (1.21)  Time: 0.262s,   15.25/s  (0.280s,   14.27/s)  LR: 1.000e-04  Data: 0.011 (0.006)\n",
      "Train: 0 [8350/9556 ( 87%)]  Loss: 1.390 (1.21)  Time: 0.279s,   14.35/s  (0.280s,   14.27/s)  LR: 1.000e-04  Data: 0.009 (0.006)\n",
      "Train: 0 [8400/9556 ( 88%)]  Loss: 1.013 (1.21)  Time: 0.256s,   15.63/s  (0.280s,   14.27/s)  LR: 1.000e-04  Data: 0.010 (0.006)\n",
      "Train: 0 [8450/9556 ( 88%)]  Loss: 0.7872 (1.21)  Time: 0.262s,   15.26/s  (0.280s,   14.27/s)  LR: 1.000e-04  Data: 0.010 (0.006)\n",
      "Train: 0 [8500/9556 ( 89%)]  Loss: 0.7688 (1.21)  Time: 0.288s,   13.87/s  (0.280s,   14.27/s)  LR: 1.000e-04  Data: 0.008 (0.006)\n",
      "Train: 0 [8550/9556 ( 89%)]  Loss: 1.070 (1.21)  Time: 0.261s,   15.34/s  (0.280s,   14.27/s)  LR: 1.000e-04  Data: 0.010 (0.006)\n",
      "Train: 0 [8600/9556 ( 90%)]  Loss: 1.444 (1.21)  Time: 0.293s,   13.63/s  (0.280s,   14.27/s)  LR: 1.000e-04  Data: 0.008 (0.006)\n",
      "Train: 0 [8650/9556 ( 91%)]  Loss: 1.087 (1.21)  Time: 0.306s,   13.07/s  (0.280s,   14.28/s)  LR: 1.000e-04  Data: 0.002 (0.006)\n",
      "Train: 0 [8700/9556 ( 91%)]  Loss: 0.5400 (1.21)  Time: 0.307s,   13.03/s  (0.280s,   14.28/s)  LR: 1.000e-04  Data: 0.006 (0.006)\n",
      "Train: 0 [8750/9556 ( 92%)]  Loss: 1.186 (1.21)  Time: 0.259s,   15.46/s  (0.280s,   14.28/s)  LR: 1.000e-04  Data: 0.005 (0.006)\n",
      "Train: 0 [8800/9556 ( 92%)]  Loss: 1.266 (1.21)  Time: 0.263s,   15.20/s  (0.280s,   14.28/s)  LR: 1.000e-04  Data: 0.009 (0.006)\n",
      "Train: 0 [8850/9556 ( 93%)]  Loss: 1.228 (1.20)  Time: 0.256s,   15.62/s  (0.280s,   14.28/s)  LR: 1.000e-04  Data: 0.010 (0.006)\n",
      "Train: 0 [8900/9556 ( 93%)]  Loss: 1.112 (1.20)  Time: 0.273s,   14.64/s  (0.280s,   14.28/s)  LR: 1.000e-04  Data: 0.002 (0.006)\n",
      "Train: 0 [8950/9556 ( 94%)]  Loss: 0.8967 (1.20)  Time: 0.305s,   13.14/s  (0.280s,   14.28/s)  LR: 1.000e-04  Data: 0.008 (0.006)\n",
      "Train: 0 [9000/9556 ( 94%)]  Loss: 1.900 (1.20)  Time: 0.275s,   14.53/s  (0.280s,   14.28/s)  LR: 1.000e-04  Data: 0.012 (0.006)\n",
      "Train: 0 [9050/9556 ( 95%)]  Loss: 0.9952 (1.20)  Time: 0.350s,   11.44/s  (0.280s,   14.28/s)  LR: 1.000e-04  Data: 0.010 (0.006)\n",
      "Train: 0 [9100/9556 ( 95%)]  Loss: 1.176 (1.20)  Time: 0.261s,   15.33/s  (0.280s,   14.28/s)  LR: 1.000e-04  Data: 0.010 (0.006)\n",
      "Train: 0 [9150/9556 ( 96%)]  Loss: 1.056 (1.20)  Time: 0.253s,   15.81/s  (0.280s,   14.29/s)  LR: 1.000e-04  Data: 0.009 (0.006)\n",
      "Train: 0 [9200/9556 ( 96%)]  Loss: 1.765 (1.20)  Time: 0.259s,   15.42/s  (0.280s,   14.29/s)  LR: 1.000e-04  Data: 0.005 (0.006)\n",
      "Train: 0 [9250/9556 ( 97%)]  Loss: 1.277 (1.20)  Time: 0.331s,   12.10/s  (0.280s,   14.29/s)  LR: 1.000e-04  Data: 0.011 (0.006)\n",
      "Train: 0 [9300/9556 ( 97%)]  Loss: 1.286 (1.20)  Time: 0.259s,   15.43/s  (0.280s,   14.29/s)  LR: 1.000e-04  Data: 0.003 (0.006)\n",
      "Train: 0 [9350/9556 ( 98%)]  Loss: 1.090 (1.20)  Time: 0.316s,   12.65/s  (0.280s,   14.29/s)  LR: 1.000e-04  Data: 0.009 (0.006)\n",
      "Train: 0 [9400/9556 ( 98%)]  Loss: 0.7061 (1.20)  Time: 0.282s,   14.20/s  (0.280s,   14.30/s)  LR: 1.000e-04  Data: 0.010 (0.006)\n",
      "Train: 0 [9450/9556 ( 99%)]  Loss: 1.074 (1.20)  Time: 0.256s,   15.64/s  (0.280s,   14.30/s)  LR: 1.000e-04  Data: 0.009 (0.006)\n",
      "Train: 0 [9500/9556 ( 99%)]  Loss: 1.001 (1.20)  Time: 0.282s,   14.20/s  (0.280s,   14.30/s)  LR: 1.000e-04  Data: 0.009 (0.006)\n",
      "Train: 0 [9550/9556 (100%)]  Loss: 0.7703 (1.20)  Time: 0.254s,   15.75/s  (0.280s,   14.30/s)  LR: 1.000e-04  Data: 0.008 (0.006)\n",
      "Train: 0 [9555/9556 (100%)]  Loss: 0.7237 (1.20)  Time: 0.274s,   14.61/s  (0.280s,   14.30/s)  LR: 1.000e-04  Data: 0.000 (0.006)\n",
      "Test: [   0/2145]  Time: 8.083 (8.083)  Loss:  0.3076 (0.3076)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [  50/2145]  Time: 0.061 (0.219)  Loss:  0.4253 (0.5850)  Acc@1: 100.0000 (84.3137)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 100/2145]  Time: 0.062 (0.142)  Loss:  0.7939 (0.6154)  Acc@1: 75.0000 (83.1683)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 150/2145]  Time: 0.061 (0.115)  Loss:  0.5273 (0.5852)  Acc@1: 100.0000 (86.9205)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 200/2145]  Time: 0.062 (0.102)  Loss:  0.5361 (0.5747)  Acc@1: 100.0000 (88.5572)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 250/2145]  Time: 0.061 (0.095)  Loss:  0.7314 (0.5916)  Acc@1: 75.0000 (88.7450)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 300/2145]  Time: 0.062 (0.090)  Loss:  0.7559 (0.5952)  Acc@1: 75.0000 (89.0365)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 350/2145]  Time: 0.069 (0.086)  Loss:  1.4033 (0.5897)  Acc@1:  0.0000 (89.3162)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 400/2145]  Time: 0.061 (0.083)  Loss:  0.4363 (0.6009)  Acc@1: 100.0000 (89.0274)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 450/2145]  Time: 0.061 (0.081)  Loss:  0.9072 (0.6087)  Acc@1: 50.0000 (87.8603)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 500/2145]  Time: 0.062 (0.079)  Loss:  0.5874 (0.6142)  Acc@1: 100.0000 (87.8743)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 550/2145]  Time: 0.062 (0.078)  Loss:  0.3982 (0.6098)  Acc@1: 100.0000 (88.6116)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 600/2145]  Time: 0.061 (0.076)  Loss:  0.7104 (0.6048)  Acc@1: 75.0000 (89.0599)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 650/2145]  Time: 0.062 (0.075)  Loss:  0.5698 (0.6004)  Acc@1: 100.0000 (89.6313)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 700/2145]  Time: 0.062 (0.074)  Loss:  0.3096 (0.6063)  Acc@1: 100.0000 (88.8017)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 750/2145]  Time: 0.063 (0.074)  Loss:  0.7339 (0.6125)  Acc@1: 100.0000 (88.5819)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 800/2145]  Time: 0.061 (0.073)  Loss:  0.4070 (0.6129)  Acc@1: 100.0000 (88.5144)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 850/2145]  Time: 0.079 (0.072)  Loss:  0.5146 (0.6110)  Acc@1: 100.0000 (88.3960)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 900/2145]  Time: 0.062 (0.072)  Loss:  0.2627 (0.6038)  Acc@1: 100.0000 (88.4018)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 950/2145]  Time: 0.069 (0.071)  Loss:  0.4160 (0.6101)  Acc@1: 100.0000 (87.7760)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1000/2145]  Time: 0.062 (0.071)  Loss:  0.4133 (0.6107)  Acc@1: 100.0000 (87.6124)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1050/2145]  Time: 0.059 (0.071)  Loss:  0.2262 (0.6121)  Acc@1: 100.0000 (87.5595)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1100/2145]  Time: 0.058 (0.070)  Loss:  0.3523 (0.6157)  Acc@1: 100.0000 (87.1480)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1150/2145]  Time: 0.061 (0.070)  Loss:  0.6904 (0.6127)  Acc@1: 50.0000 (87.0982)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1200/2145]  Time: 0.072 (0.070)  Loss:  0.5093 (0.6121)  Acc@1: 100.0000 (87.0733)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1250/2145]  Time: 0.062 (0.069)  Loss:  2.4062 (0.6244)  Acc@1:  0.0000 (86.4309)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1300/2145]  Time: 0.058 (0.069)  Loss:  2.2773 (0.6731)  Acc@1:  0.0000 (83.1860)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1350/2145]  Time: 0.063 (0.069)  Loss:  1.8887 (0.7271)  Acc@1:  0.0000 (80.3479)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1400/2145]  Time: 0.061 (0.069)  Loss:  2.1484 (0.7734)  Acc@1:  0.0000 (77.7480)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1450/2145]  Time: 0.062 (0.068)  Loss:  2.3984 (0.8363)  Acc@1:  0.0000 (75.0689)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1500/2145]  Time: 0.066 (0.068)  Loss:  1.4961 (0.8810)  Acc@1:  0.0000 (72.6516)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1550/2145]  Time: 0.078 (0.068)  Loss:  1.1826 (0.9092)  Acc@1:  0.0000 (70.5190)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1600/2145]  Time: 0.062 (0.068)  Loss:  1.6162 (0.9334)  Acc@1:  0.0000 (68.4884)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1650/2145]  Time: 0.061 (0.068)  Loss:  2.5410 (0.9596)  Acc@1:  0.0000 (66.5506)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1700/2145]  Time: 0.058 (0.068)  Loss:  1.5801 (0.9795)  Acc@1:  0.0000 (64.9030)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1750/2145]  Time: 0.062 (0.068)  Loss:  2.0645 (0.9977)  Acc@1:  0.0000 (63.2638)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1800/2145]  Time: 0.061 (0.067)  Loss:  1.1084 (1.0146)  Acc@1: 25.0000 (61.7435)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1850/2145]  Time: 0.061 (0.067)  Loss:  1.3037 (1.0268)  Acc@1:  0.0000 (60.3593)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1900/2145]  Time: 0.062 (0.067)  Loss:  2.4258 (1.0370)  Acc@1:  0.0000 (59.1794)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1950/2145]  Time: 0.062 (0.067)  Loss:  1.5801 (1.0510)  Acc@1: 25.0000 (58.0215)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [2000/2145]  Time: 0.061 (0.067)  Loss:  1.1865 (1.0562)  Acc@1: 25.0000 (57.0215)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [2050/2145]  Time: 0.057 (0.067)  Loss:  1.1934 (1.0629)  Acc@1:  0.0000 (55.8874)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [2100/2145]  Time: 0.062 (0.067)  Loss:  1.9922 (1.0711)  Acc@1:  0.0000 (54.8191)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [2145/2145]  Time: 9.496 (0.071)  Loss:  3.1523 (1.0989)  Acc@1:  0.0000 (53.7341)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train\\\\dfl-benchmark-training-fix-extract-images\\\\checkpoint-0.pth.tar', 53.73412559711057)\n",
      "\n",
      "Train: 1 [   0/9556 (  0%)]  Loss: 1.392 (1.39)  Time: 0.574s,    6.97/s  (0.574s,    6.97/s)  LR: 1.673e-02  Data: 0.241 (0.241)\n",
      "Train: 1 [  50/9556 (  1%)]  Loss: 1.889 (2.48)  Time: 0.251s,   15.93/s  (0.268s,   14.93/s)  LR: 1.673e-02  Data: 0.003 (0.012)\n",
      "Train: 1 [ 100/9556 (  1%)]  Loss: 1.308 (1.90)  Time: 0.304s,   13.14/s  (0.272s,   14.71/s)  LR: 1.673e-02  Data: 0.002 (0.010)\n",
      "Train: 1 [ 150/9556 (  2%)]  Loss: 1.203 (1.68)  Time: 0.251s,   15.94/s  (0.274s,   14.60/s)  LR: 1.673e-02  Data: 0.010 (0.009)\n",
      "Train: 1 [ 200/9556 (  2%)]  Loss: 1.058 (1.57)  Time: 0.322s,   12.43/s  (0.274s,   14.58/s)  LR: 1.673e-02  Data: 0.003 (0.009)\n",
      "Train: 1 [ 250/9556 (  3%)]  Loss: 1.213 (1.47)  Time: 0.292s,   13.68/s  (0.275s,   14.52/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [ 300/9556 (  3%)]  Loss: 0.8885 (1.41)  Time: 0.274s,   14.61/s  (0.275s,   14.56/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [ 350/9556 (  4%)]  Loss: 1.196 (1.38)  Time: 0.276s,   14.49/s  (0.276s,   14.51/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [ 400/9556 (  4%)]  Loss: 1.323 (1.35)  Time: 0.254s,   15.77/s  (0.275s,   14.56/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [ 450/9556 (  5%)]  Loss: 2.085 (1.34)  Time: 0.250s,   16.00/s  (0.274s,   14.61/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [ 500/9556 (  5%)]  Loss: 1.108 (1.32)  Time: 0.251s,   15.95/s  (0.274s,   14.59/s)  LR: 1.673e-02  Data: 0.008 (0.008)\n",
      "Train: 1 [ 550/9556 (  6%)]  Loss: 1.076 (1.31)  Time: 0.253s,   15.83/s  (0.275s,   14.56/s)  LR: 1.673e-02  Data: 0.011 (0.008)\n",
      "Train: 1 [ 600/9556 (  6%)]  Loss: 1.344 (1.29)  Time: 0.267s,   15.01/s  (0.274s,   14.59/s)  LR: 1.673e-02  Data: 0.008 (0.008)\n",
      "Train: 1 [ 650/9556 (  7%)]  Loss: 1.759 (1.28)  Time: 0.296s,   13.50/s  (0.274s,   14.60/s)  LR: 1.673e-02  Data: 0.008 (0.008)\n",
      "Train: 1 [ 700/9556 (  7%)]  Loss: 1.423 (1.27)  Time: 0.294s,   13.59/s  (0.274s,   14.60/s)  LR: 1.673e-02  Data: 0.003 (0.008)\n",
      "Train: 1 [ 750/9556 (  8%)]  Loss: 1.220 (1.27)  Time: 0.250s,   15.97/s  (0.274s,   14.62/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [ 800/9556 (  8%)]  Loss: 1.504 (1.26)  Time: 0.245s,   16.31/s  (0.274s,   14.62/s)  LR: 1.673e-02  Data: 0.002 (0.008)\n",
      "Train: 1 [ 850/9556 (  9%)]  Loss: 1.013 (1.25)  Time: 0.299s,   13.37/s  (0.273s,   14.63/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [ 900/9556 (  9%)]  Loss: 1.043 (1.24)  Time: 0.256s,   15.61/s  (0.273s,   14.65/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [ 950/9556 ( 10%)]  Loss: 0.7788 (1.24)  Time: 0.304s,   13.16/s  (0.273s,   14.64/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [1000/9556 ( 10%)]  Loss: 1.254 (1.23)  Time: 0.299s,   13.37/s  (0.273s,   14.63/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [1050/9556 ( 11%)]  Loss: 0.8518 (1.23)  Time: 0.267s,   14.96/s  (0.273s,   14.64/s)  LR: 1.673e-02  Data: 0.007 (0.008)\n",
      "Train: 1 [1100/9556 ( 12%)]  Loss: 0.7902 (1.22)  Time: 0.298s,   13.41/s  (0.273s,   14.64/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [1150/9556 ( 12%)]  Loss: 1.439 (1.22)  Time: 0.335s,   11.95/s  (0.273s,   14.63/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [1200/9556 ( 13%)]  Loss: 1.297 (1.21)  Time: 0.249s,   16.09/s  (0.273s,   14.64/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [1250/9556 ( 13%)]  Loss: 1.058 (1.21)  Time: 0.270s,   14.81/s  (0.273s,   14.65/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [1300/9556 ( 14%)]  Loss: 0.9127 (1.20)  Time: 0.261s,   15.32/s  (0.273s,   14.65/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [1350/9556 ( 14%)]  Loss: 1.072 (1.20)  Time: 0.251s,   15.92/s  (0.273s,   14.65/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [1400/9556 ( 15%)]  Loss: 0.8003 (1.20)  Time: 0.284s,   14.08/s  (0.273s,   14.67/s)  LR: 1.673e-02  Data: 0.012 (0.008)\n",
      "Train: 1 [1450/9556 ( 15%)]  Loss: 0.6299 (1.20)  Time: 0.258s,   15.50/s  (0.273s,   14.67/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [1500/9556 ( 16%)]  Loss: 0.7211 (1.19)  Time: 0.298s,   13.41/s  (0.273s,   14.68/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [1550/9556 ( 16%)]  Loss: 1.402 (1.19)  Time: 0.288s,   13.87/s  (0.273s,   14.67/s)  LR: 1.673e-02  Data: 0.001 (0.008)\n",
      "Train: 1 [1600/9556 ( 17%)]  Loss: 1.280 (1.19)  Time: 0.251s,   15.94/s  (0.272s,   14.68/s)  LR: 1.673e-02  Data: 0.008 (0.008)\n",
      "Train: 1 [1650/9556 ( 17%)]  Loss: 1.021 (1.19)  Time: 0.245s,   16.33/s  (0.272s,   14.69/s)  LR: 1.673e-02  Data: 0.002 (0.008)\n",
      "Train: 1 [1700/9556 ( 18%)]  Loss: 1.377 (1.19)  Time: 0.252s,   15.86/s  (0.272s,   14.69/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [1750/9556 ( 18%)]  Loss: 1.247 (1.19)  Time: 0.249s,   16.08/s  (0.272s,   14.70/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [1800/9556 ( 19%)]  Loss: 1.110 (1.19)  Time: 0.267s,   15.00/s  (0.272s,   14.69/s)  LR: 1.673e-02  Data: 0.002 (0.008)\n",
      "Train: 1 [1850/9556 ( 19%)]  Loss: 0.3919 (1.18)  Time: 0.347s,   11.53/s  (0.272s,   14.69/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [1900/9556 ( 20%)]  Loss: 1.220 (1.18)  Time: 0.340s,   11.75/s  (0.272s,   14.69/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [1950/9556 ( 20%)]  Loss: 1.024 (1.18)  Time: 0.311s,   12.86/s  (0.272s,   14.68/s)  LR: 1.673e-02  Data: 0.015 (0.008)\n",
      "Train: 1 [2000/9556 ( 21%)]  Loss: 0.7871 (1.18)  Time: 0.339s,   11.79/s  (0.272s,   14.69/s)  LR: 1.673e-02  Data: 0.002 (0.008)\n",
      "Train: 1 [2050/9556 ( 21%)]  Loss: 1.150 (1.18)  Time: 0.257s,   15.54/s  (0.272s,   14.69/s)  LR: 1.673e-02  Data: 0.005 (0.008)\n",
      "Train: 1 [2100/9556 ( 22%)]  Loss: 0.7801 (1.17)  Time: 0.260s,   15.38/s  (0.272s,   14.70/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [2150/9556 ( 23%)]  Loss: 1.034 (1.17)  Time: 0.257s,   15.55/s  (0.272s,   14.70/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [2200/9556 ( 23%)]  Loss: 1.647 (1.17)  Time: 0.253s,   15.79/s  (0.272s,   14.69/s)  LR: 1.673e-02  Data: 0.011 (0.008)\n",
      "Train: 1 [2250/9556 ( 24%)]  Loss: 0.8309 (1.17)  Time: 0.251s,   15.91/s  (0.272s,   14.71/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [2300/9556 ( 24%)]  Loss: 1.734 (1.17)  Time: 0.252s,   15.88/s  (0.272s,   14.72/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [2350/9556 ( 25%)]  Loss: 1.115 (1.17)  Time: 0.251s,   15.94/s  (0.272s,   14.72/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [2400/9556 ( 25%)]  Loss: 1.167 (1.17)  Time: 0.256s,   15.64/s  (0.272s,   14.71/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [2450/9556 ( 26%)]  Loss: 1.299 (1.17)  Time: 0.252s,   15.88/s  (0.272s,   14.72/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [2500/9556 ( 26%)]  Loss: 0.8452 (1.16)  Time: 0.262s,   15.27/s  (0.272s,   14.72/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [2550/9556 ( 27%)]  Loss: 1.338 (1.16)  Time: 0.280s,   14.27/s  (0.272s,   14.72/s)  LR: 1.673e-02  Data: 0.007 (0.008)\n",
      "Train: 1 [2600/9556 ( 27%)]  Loss: 1.011 (1.16)  Time: 0.253s,   15.80/s  (0.272s,   14.72/s)  LR: 1.673e-02  Data: 0.002 (0.008)\n",
      "Train: 1 [2650/9556 ( 28%)]  Loss: 0.8894 (1.16)  Time: 0.253s,   15.80/s  (0.272s,   14.73/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [2700/9556 ( 28%)]  Loss: 0.8540 (1.16)  Time: 0.251s,   15.91/s  (0.272s,   14.73/s)  LR: 1.673e-02  Data: 0.002 (0.008)\n",
      "Train: 1 [2750/9556 ( 29%)]  Loss: 0.9972 (1.16)  Time: 0.339s,   11.80/s  (0.272s,   14.73/s)  LR: 1.673e-02  Data: 0.005 (0.008)\n",
      "Train: 1 [2800/9556 ( 29%)]  Loss: 0.8747 (1.16)  Time: 0.274s,   14.58/s  (0.272s,   14.73/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [2850/9556 ( 30%)]  Loss: 0.4805 (1.16)  Time: 0.258s,   15.52/s  (0.271s,   14.74/s)  LR: 1.673e-02  Data: 0.008 (0.008)\n",
      "Train: 1 [2900/9556 ( 30%)]  Loss: 0.8141 (1.16)  Time: 0.289s,   13.83/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [2950/9556 ( 31%)]  Loss: 0.5551 (1.15)  Time: 0.295s,   13.56/s  (0.271s,   14.74/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [3000/9556 ( 31%)]  Loss: 1.488 (1.15)  Time: 0.290s,   13.80/s  (0.271s,   14.74/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [3050/9556 ( 32%)]  Loss: 0.4808 (1.15)  Time: 0.282s,   14.17/s  (0.271s,   14.74/s)  LR: 1.673e-02  Data: 0.012 (0.008)\n",
      "Train: 1 [3100/9556 ( 32%)]  Loss: 0.6785 (1.15)  Time: 0.247s,   16.20/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.005 (0.008)\n",
      "Train: 1 [3150/9556 ( 33%)]  Loss: 1.155 (1.15)  Time: 0.250s,   15.98/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.008 (0.008)\n",
      "Train: 1 [3200/9556 ( 33%)]  Loss: 1.649 (1.15)  Time: 0.264s,   15.14/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [3250/9556 ( 34%)]  Loss: 1.519 (1.15)  Time: 0.302s,   13.24/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.008 (0.008)\n",
      "Train: 1 [3300/9556 ( 35%)]  Loss: 0.8055 (1.15)  Time: 0.277s,   14.43/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.011 (0.008)\n",
      "Train: 1 [3350/9556 ( 35%)]  Loss: 1.030 (1.15)  Time: 0.259s,   15.42/s  (0.271s,   14.76/s)  LR: 1.673e-02  Data: 0.011 (0.008)\n",
      "Train: 1 [3400/9556 ( 36%)]  Loss: 0.9235 (1.15)  Time: 0.248s,   16.10/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.010 (0.008)\n",
      "Train: 1 [3450/9556 ( 36%)]  Loss: 0.6281 (1.15)  Time: 0.274s,   14.60/s  (0.271s,   14.76/s)  LR: 1.673e-02  Data: 0.006 (0.008)\n",
      "Train: 1 [3500/9556 ( 37%)]  Loss: 1.205 (1.15)  Time: 0.254s,   15.74/s  (0.271s,   14.76/s)  LR: 1.673e-02  Data: 0.003 (0.008)\n",
      "Train: 1 [3550/9556 ( 37%)]  Loss: 1.772 (1.15)  Time: 0.333s,   11.99/s  (0.271s,   14.76/s)  LR: 1.673e-02  Data: 0.001 (0.008)\n",
      "Train: 1 [3600/9556 ( 38%)]  Loss: 0.7703 (1.15)  Time: 0.252s,   15.84/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [3650/9556 ( 38%)]  Loss: 0.8831 (1.15)  Time: 0.261s,   15.31/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.009 (0.008)\n",
      "Train: 1 [3700/9556 ( 39%)]  Loss: 0.7792 (1.14)  Time: 0.268s,   14.95/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.002 (0.008)\n",
      "Train: 1 [3750/9556 ( 39%)]  Loss: 0.8501 (1.14)  Time: 0.290s,   13.79/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.005 (0.007)\n",
      "Train: 1 [3800/9556 ( 40%)]  Loss: 1.159 (1.14)  Time: 0.304s,   13.17/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.010 (0.007)\n",
      "Train: 1 [3850/9556 ( 40%)]  Loss: 1.331 (1.14)  Time: 0.286s,   13.97/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.011 (0.007)\n",
      "Train: 1 [3900/9556 ( 41%)]  Loss: 1.434 (1.14)  Time: 0.254s,   15.74/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.004 (0.007)\n",
      "Train: 1 [3950/9556 ( 41%)]  Loss: 1.330 (1.14)  Time: 0.253s,   15.79/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.009 (0.007)\n",
      "Train: 1 [4000/9556 ( 42%)]  Loss: 1.313 (1.14)  Time: 0.255s,   15.68/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.002 (0.007)\n",
      "Train: 1 [4050/9556 ( 42%)]  Loss: 1.156 (1.14)  Time: 0.308s,   13.01/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.010 (0.007)\n",
      "Train: 1 [4100/9556 ( 43%)]  Loss: 0.7310 (1.14)  Time: 0.250s,   15.97/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.010 (0.007)\n",
      "Train: 1 [4150/9556 ( 43%)]  Loss: 1.657 (1.14)  Time: 0.307s,   13.01/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.002 (0.007)\n",
      "Train: 1 [4200/9556 ( 44%)]  Loss: 0.9903 (1.14)  Time: 0.253s,   15.81/s  (0.271s,   14.75/s)  LR: 1.673e-02  Data: 0.003 (0.007)\n",
      "Train: 1 [4250/9556 ( 44%)]  Loss: 1.115 (1.14)  Time: 0.251s,   15.93/s  (0.271s,   14.76/s)  LR: 1.673e-02  Data: 0.008 (0.007)\n",
      "Train: 1 [4300/9556 ( 45%)]  Loss: 2.124 (1.14)  Time: 0.247s,   16.21/s  (0.271s,   14.76/s)  LR: 1.673e-02  Data: 0.002 (0.007)\n",
      "Train: 1 [4350/9556 ( 46%)]  Loss: 0.9826 (1.14)  Time: 0.254s,   15.73/s  (0.271s,   14.76/s)  LR: 1.673e-02  Data: 0.009 (0.007)\n",
      "Train: 1 [4400/9556 ( 46%)]  Loss: 1.156 (1.14)  Time: 0.271s,   14.76/s  (0.271s,   14.76/s)  LR: 1.673e-02  Data: 0.008 (0.007)\n",
      "Train: 1 [4450/9556 ( 47%)]  Loss: 1.520 (1.14)  Time: 0.303s,   13.20/s  (0.271s,   14.76/s)  LR: 1.673e-02  Data: 0.003 (0.007)\n",
      "Train: 1 [4500/9556 ( 47%)]  Loss: 0.9595 (1.14)  Time: 0.296s,   13.52/s  (0.271s,   14.77/s)  LR: 1.673e-02  Data: 0.009 (0.007)\n",
      "Train: 1 [4550/9556 ( 48%)]  Loss: 1.180 (1.14)  Time: 0.249s,   16.04/s  (0.271s,   14.77/s)  LR: 1.673e-02  Data: 0.002 (0.007)\n",
      "Train: 1 [4600/9556 ( 48%)]  Loss: 1.544 (1.14)  Time: 0.259s,   15.46/s  (0.271s,   14.77/s)  LR: 1.673e-02  Data: 0.010 (0.007)\n",
      "Train: 1 [4650/9556 ( 49%)]  Loss: 1.051 (1.14)  Time: 0.296s,   13.51/s  (0.271s,   14.77/s)  LR: 1.673e-02  Data: 0.009 (0.007)\n",
      "Train: 1 [4700/9556 ( 49%)]  Loss: 1.238 (1.14)  Time: 0.245s,   16.33/s  (0.271s,   14.77/s)  LR: 1.673e-02  Data: 0.004 (0.007)\n",
      "Train: 1 [4750/9556 ( 50%)]  Loss: 0.9257 (1.14)  Time: 0.254s,   15.74/s  (0.271s,   14.77/s)  LR: 1.673e-02  Data: 0.005 (0.007)\n",
      "Train: 1 [4800/9556 ( 50%)]  Loss: 0.9700 (1.14)  Time: 0.270s,   14.82/s  (0.271s,   14.77/s)  LR: 1.673e-02  Data: 0.002 (0.007)\n",
      "Train: 1 [4850/9556 ( 51%)]  Loss: 0.9118 (1.14)  Time: 0.254s,   15.74/s  (0.271s,   14.78/s)  LR: 1.673e-02  Data: 0.003 (0.007)\n",
      "Train: 1 [4900/9556 ( 51%)]  Loss: 1.058 (1.14)  Time: 0.257s,   15.59/s  (0.271s,   14.78/s)  LR: 1.673e-02  Data: 0.002 (0.007)\n",
      "Train: 1 [4950/9556 ( 52%)]  Loss: 0.8703 (1.14)  Time: 0.252s,   15.84/s  (0.271s,   14.78/s)  LR: 1.673e-02  Data: 0.001 (0.007)\n",
      "Train: 1 [5000/9556 ( 52%)]  Loss: 0.7759 (1.14)  Time: 0.282s,   14.19/s  (0.271s,   14.79/s)  LR: 1.673e-02  Data: 0.003 (0.007)\n",
      "Train: 1 [5050/9556 ( 53%)]  Loss: 1.293 (1.14)  Time: 0.275s,   14.57/s  (0.270s,   14.79/s)  LR: 1.673e-02  Data: 0.003 (0.007)\n",
      "Train: 1 [5100/9556 ( 53%)]  Loss: 0.9275 (1.14)  Time: 0.254s,   15.74/s  (0.270s,   14.80/s)  LR: 1.673e-02  Data: 0.002 (0.007)\n",
      "Train: 1 [5150/9556 ( 54%)]  Loss: 0.8681 (1.14)  Time: 0.249s,   16.04/s  (0.270s,   14.80/s)  LR: 1.673e-02  Data: 0.002 (0.007)\n",
      "Train: 1 [5200/9556 ( 54%)]  Loss: 1.004 (1.14)  Time: 0.254s,   15.76/s  (0.270s,   14.80/s)  LR: 1.673e-02  Data: 0.003 (0.007)\n",
      "Train: 1 [5250/9556 ( 55%)]  Loss: 1.221 (1.14)  Time: 0.251s,   15.92/s  (0.270s,   14.81/s)  LR: 1.673e-02  Data: 0.003 (0.007)\n",
      "Train: 1 [5300/9556 ( 55%)]  Loss: 1.245 (1.14)  Time: 0.255s,   15.69/s  (0.270s,   14.81/s)  LR: 1.673e-02  Data: 0.002 (0.007)\n",
      "Train: 1 [5350/9556 ( 56%)]  Loss: 0.9138 (1.14)  Time: 0.258s,   15.51/s  (0.270s,   14.81/s)  LR: 1.673e-02  Data: 0.003 (0.007)\n",
      "Train: 1 [5400/9556 ( 57%)]  Loss: 0.9873 (1.14)  Time: 0.253s,   15.80/s  (0.270s,   14.82/s)  LR: 1.673e-02  Data: 0.001 (0.007)\n",
      "Train: 1 [5450/9556 ( 57%)]  Loss: 1.071 (1.14)  Time: 0.253s,   15.81/s  (0.270s,   14.82/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [5500/9556 ( 58%)]  Loss: 1.312 (1.14)  Time: 0.276s,   14.51/s  (0.270s,   14.82/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [5550/9556 ( 58%)]  Loss: 0.7784 (1.14)  Time: 0.279s,   14.36/s  (0.270s,   14.83/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [5600/9556 ( 59%)]  Loss: 0.9661 (1.13)  Time: 0.294s,   13.58/s  (0.270s,   14.83/s)  LR: 1.673e-02  Data: 0.003 (0.006)\n",
      "Train: 1 [5650/9556 ( 59%)]  Loss: 1.019 (1.13)  Time: 0.266s,   15.07/s  (0.270s,   14.84/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [5700/9556 ( 60%)]  Loss: 1.180 (1.13)  Time: 0.279s,   14.33/s  (0.270s,   14.84/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [5750/9556 ( 60%)]  Loss: 0.7412 (1.13)  Time: 0.305s,   13.12/s  (0.269s,   14.84/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [5800/9556 ( 61%)]  Loss: 0.8711 (1.13)  Time: 0.281s,   14.21/s  (0.269s,   14.85/s)  LR: 1.673e-02  Data: 0.003 (0.006)\n",
      "Train: 1 [5850/9556 ( 61%)]  Loss: 1.164 (1.13)  Time: 0.275s,   14.57/s  (0.269s,   14.85/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [5900/9556 ( 62%)]  Loss: 1.032 (1.13)  Time: 0.253s,   15.81/s  (0.269s,   14.85/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [5950/9556 ( 62%)]  Loss: 1.208 (1.13)  Time: 0.276s,   14.50/s  (0.269s,   14.85/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [6000/9556 ( 63%)]  Loss: 1.094 (1.13)  Time: 0.256s,   15.63/s  (0.269s,   14.85/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [6050/9556 ( 63%)]  Loss: 1.295 (1.13)  Time: 0.263s,   15.21/s  (0.269s,   14.86/s)  LR: 1.673e-02  Data: 0.005 (0.006)\n",
      "Train: 1 [6100/9556 ( 64%)]  Loss: 1.704 (1.13)  Time: 0.271s,   14.75/s  (0.269s,   14.85/s)  LR: 1.673e-02  Data: 0.003 (0.006)\n",
      "Train: 1 [6150/9556 ( 64%)]  Loss: 1.015 (1.13)  Time: 0.257s,   15.56/s  (0.269s,   14.85/s)  LR: 1.673e-02  Data: 0.003 (0.006)\n",
      "Train: 1 [6200/9556 ( 65%)]  Loss: 1.002 (1.13)  Time: 0.254s,   15.74/s  (0.269s,   14.85/s)  LR: 1.673e-02  Data: 0.003 (0.006)\n",
      "Train: 1 [6250/9556 ( 65%)]  Loss: 1.323 (1.13)  Time: 0.271s,   14.76/s  (0.269s,   14.85/s)  LR: 1.673e-02  Data: 0.003 (0.006)\n",
      "Train: 1 [6300/9556 ( 66%)]  Loss: 0.8160 (1.13)  Time: 0.274s,   14.59/s  (0.269s,   14.86/s)  LR: 1.673e-02  Data: 0.007 (0.006)\n",
      "Train: 1 [6350/9556 ( 66%)]  Loss: 1.135 (1.13)  Time: 0.254s,   15.76/s  (0.269s,   14.86/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [6400/9556 ( 67%)]  Loss: 0.9516 (1.13)  Time: 0.281s,   14.24/s  (0.269s,   14.86/s)  LR: 1.673e-02  Data: 0.005 (0.006)\n",
      "Train: 1 [6450/9556 ( 68%)]  Loss: 0.8486 (1.13)  Time: 0.274s,   14.59/s  (0.269s,   14.86/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [6500/9556 ( 68%)]  Loss: 1.250 (1.13)  Time: 0.248s,   16.11/s  (0.269s,   14.87/s)  LR: 1.673e-02  Data: 0.006 (0.006)\n",
      "Train: 1 [6550/9556 ( 69%)]  Loss: 0.9879 (1.13)  Time: 0.282s,   14.18/s  (0.269s,   14.87/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [6600/9556 ( 69%)]  Loss: 0.7416 (1.13)  Time: 0.260s,   15.36/s  (0.269s,   14.87/s)  LR: 1.673e-02  Data: 0.003 (0.006)\n",
      "Train: 1 [6650/9556 ( 70%)]  Loss: 0.9633 (1.13)  Time: 0.249s,   16.07/s  (0.269s,   14.87/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [6700/9556 ( 70%)]  Loss: 1.176 (1.13)  Time: 0.295s,   13.57/s  (0.269s,   14.88/s)  LR: 1.673e-02  Data: 0.003 (0.006)\n",
      "Train: 1 [6750/9556 ( 71%)]  Loss: 1.301 (1.13)  Time: 0.260s,   15.38/s  (0.269s,   14.88/s)  LR: 1.673e-02  Data: 0.010 (0.006)\n",
      "Train: 1 [6800/9556 ( 71%)]  Loss: 1.116 (1.13)  Time: 0.272s,   14.72/s  (0.269s,   14.88/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [6850/9556 ( 72%)]  Loss: 1.794 (1.13)  Time: 0.339s,   11.81/s  (0.269s,   14.88/s)  LR: 1.673e-02  Data: 0.010 (0.006)\n",
      "Train: 1 [6900/9556 ( 72%)]  Loss: 1.163 (1.13)  Time: 0.254s,   15.75/s  (0.269s,   14.88/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [6950/9556 ( 73%)]  Loss: 1.406 (1.13)  Time: 0.252s,   15.87/s  (0.269s,   14.88/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [7000/9556 ( 73%)]  Loss: 1.075 (1.13)  Time: 0.253s,   15.78/s  (0.269s,   14.88/s)  LR: 1.673e-02  Data: 0.004 (0.006)\n",
      "Train: 1 [7050/9556 ( 74%)]  Loss: 0.8422 (1.13)  Time: 0.253s,   15.81/s  (0.269s,   14.89/s)  LR: 1.673e-02  Data: 0.004 (0.006)\n",
      "Train: 1 [7100/9556 ( 74%)]  Loss: 1.038 (1.13)  Time: 0.256s,   15.64/s  (0.269s,   14.89/s)  LR: 1.673e-02  Data: 0.004 (0.006)\n",
      "Train: 1 [7150/9556 ( 75%)]  Loss: 0.9904 (1.12)  Time: 0.251s,   15.92/s  (0.269s,   14.89/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [7200/9556 ( 75%)]  Loss: 0.8843 (1.12)  Time: 0.254s,   15.74/s  (0.269s,   14.89/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [7250/9556 ( 76%)]  Loss: 0.9958 (1.12)  Time: 0.274s,   14.59/s  (0.269s,   14.89/s)  LR: 1.673e-02  Data: 0.007 (0.006)\n",
      "Train: 1 [7300/9556 ( 76%)]  Loss: 0.8525 (1.12)  Time: 0.259s,   15.46/s  (0.269s,   14.90/s)  LR: 1.673e-02  Data: 0.009 (0.006)\n",
      "Train: 1 [7350/9556 ( 77%)]  Loss: 1.355 (1.12)  Time: 0.260s,   15.37/s  (0.268s,   14.90/s)  LR: 1.673e-02  Data: 0.008 (0.006)\n",
      "Train: 1 [7400/9556 ( 77%)]  Loss: 1.398 (1.12)  Time: 0.270s,   14.79/s  (0.268s,   14.90/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [7450/9556 ( 78%)]  Loss: 1.634 (1.12)  Time: 0.280s,   14.27/s  (0.268s,   14.90/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [7500/9556 ( 78%)]  Loss: 0.9669 (1.12)  Time: 0.252s,   15.86/s  (0.268s,   14.90/s)  LR: 1.673e-02  Data: 0.001 (0.006)\n",
      "Train: 1 [7550/9556 ( 79%)]  Loss: 1.526 (1.12)  Time: 0.282s,   14.20/s  (0.268s,   14.90/s)  LR: 1.673e-02  Data: 0.004 (0.006)\n",
      "Train: 1 [7600/9556 ( 80%)]  Loss: 0.8162 (1.12)  Time: 0.262s,   15.26/s  (0.268s,   14.91/s)  LR: 1.673e-02  Data: 0.004 (0.006)\n",
      "Train: 1 [7650/9556 ( 80%)]  Loss: 0.8803 (1.12)  Time: 0.259s,   15.43/s  (0.268s,   14.91/s)  LR: 1.673e-02  Data: 0.010 (0.006)\n",
      "Train: 1 [7700/9556 ( 81%)]  Loss: 1.217 (1.12)  Time: 0.257s,   15.58/s  (0.268s,   14.91/s)  LR: 1.673e-02  Data: 0.005 (0.006)\n",
      "Train: 1 [7750/9556 ( 81%)]  Loss: 0.7264 (1.12)  Time: 0.252s,   15.86/s  (0.268s,   14.91/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [7800/9556 ( 82%)]  Loss: 1.219 (1.12)  Time: 0.279s,   14.36/s  (0.268s,   14.91/s)  LR: 1.673e-02  Data: 0.003 (0.006)\n",
      "Train: 1 [7850/9556 ( 82%)]  Loss: 0.9397 (1.12)  Time: 0.253s,   15.79/s  (0.268s,   14.91/s)  LR: 1.673e-02  Data: 0.002 (0.006)\n",
      "Train: 1 [7900/9556 ( 83%)]  Loss: 0.7885 (1.12)  Time: 0.276s,   14.49/s  (0.268s,   14.92/s)  LR: 1.673e-02  Data: 0.003 (0.006)\n",
      "Train: 1 [7950/9556 ( 83%)]  Loss: 1.052 (1.12)  Time: 0.302s,   13.23/s  (0.268s,   14.92/s)  LR: 1.673e-02  Data: 0.003 (0.006)\n",
      "Train: 1 [8000/9556 ( 84%)]  Loss: 1.246 (1.12)  Time: 0.256s,   15.62/s  (0.268s,   14.92/s)  LR: 1.673e-02  Data: 0.004 (0.006)\n",
      "Train: 1 [8050/9556 ( 84%)]  Loss: 1.130 (1.12)  Time: 0.253s,   15.82/s  (0.268s,   14.92/s)  LR: 1.673e-02  Data: 0.003 (0.006)\n",
      "Train: 1 [8100/9556 ( 85%)]  Loss: 1.425 (1.12)  Time: 0.275s,   14.57/s  (0.268s,   14.92/s)  LR: 1.673e-02  Data: 0.007 (0.006)\n",
      "Train: 1 [8150/9556 ( 85%)]  Loss: 1.701 (1.12)  Time: 0.258s,   15.49/s  (0.268s,   14.93/s)  LR: 1.673e-02  Data: 0.001 (0.005)\n",
      "Train: 1 [8200/9556 ( 86%)]  Loss: 1.018 (1.12)  Time: 0.280s,   14.30/s  (0.268s,   14.93/s)  LR: 1.673e-02  Data: 0.003 (0.005)\n",
      "Train: 1 [8250/9556 ( 86%)]  Loss: 0.7451 (1.12)  Time: 0.260s,   15.40/s  (0.268s,   14.93/s)  LR: 1.673e-02  Data: 0.006 (0.005)\n",
      "Train: 1 [8300/9556 ( 87%)]  Loss: 1.021 (1.12)  Time: 0.259s,   15.42/s  (0.268s,   14.93/s)  LR: 1.673e-02  Data: 0.008 (0.005)\n",
      "Train: 1 [8350/9556 ( 87%)]  Loss: 1.007 (1.12)  Time: 0.276s,   14.48/s  (0.268s,   14.93/s)  LR: 1.673e-02  Data: 0.002 (0.005)\n",
      "Train: 1 [8400/9556 ( 88%)]  Loss: 0.9634 (1.12)  Time: 0.287s,   13.92/s  (0.268s,   14.94/s)  LR: 1.673e-02  Data: 0.011 (0.005)\n",
      "Train: 1 [8450/9556 ( 88%)]  Loss: 0.8899 (1.12)  Time: 0.255s,   15.69/s  (0.268s,   14.94/s)  LR: 1.673e-02  Data: 0.006 (0.005)\n",
      "Train: 1 [8500/9556 ( 89%)]  Loss: 0.8300 (1.12)  Time: 0.255s,   15.67/s  (0.268s,   14.94/s)  LR: 1.673e-02  Data: 0.004 (0.005)\n",
      "Train: 1 [8550/9556 ( 89%)]  Loss: 0.8169 (1.12)  Time: 0.267s,   14.98/s  (0.268s,   14.94/s)  LR: 1.673e-02  Data: 0.002 (0.005)\n",
      "Train: 1 [8600/9556 ( 90%)]  Loss: 0.8680 (1.12)  Time: 0.252s,   15.87/s  (0.268s,   14.95/s)  LR: 1.673e-02  Data: 0.002 (0.005)\n",
      "Train: 1 [8650/9556 ( 91%)]  Loss: 1.301 (1.12)  Time: 0.246s,   16.27/s  (0.268s,   14.95/s)  LR: 1.673e-02  Data: 0.002 (0.005)\n",
      "Train: 1 [8700/9556 ( 91%)]  Loss: 0.8404 (1.12)  Time: 0.247s,   16.17/s  (0.268s,   14.95/s)  LR: 1.673e-02  Data: 0.002 (0.005)\n",
      "Train: 1 [8750/9556 ( 92%)]  Loss: 1.205 (1.12)  Time: 0.283s,   14.11/s  (0.268s,   14.95/s)  LR: 1.673e-02  Data: 0.010 (0.005)\n",
      "Train: 1 [8800/9556 ( 92%)]  Loss: 1.104 (1.12)  Time: 0.247s,   16.17/s  (0.267s,   14.95/s)  LR: 1.673e-02  Data: 0.004 (0.005)\n",
      "Train: 1 [8850/9556 ( 93%)]  Loss: 1.275 (1.12)  Time: 0.256s,   15.61/s  (0.267s,   14.96/s)  LR: 1.673e-02  Data: 0.009 (0.005)\n",
      "Train: 1 [8900/9556 ( 93%)]  Loss: 0.7444 (1.12)  Time: 0.254s,   15.73/s  (0.267s,   14.96/s)  LR: 1.673e-02  Data: 0.002 (0.005)\n",
      "Train: 1 [8950/9556 ( 94%)]  Loss: 1.126 (1.12)  Time: 0.276s,   14.49/s  (0.267s,   14.96/s)  LR: 1.673e-02  Data: 0.003 (0.005)\n",
      "Train: 1 [9000/9556 ( 94%)]  Loss: 1.244 (1.12)  Time: 0.255s,   15.71/s  (0.267s,   14.96/s)  LR: 1.673e-02  Data: 0.002 (0.005)\n",
      "Train: 1 [9050/9556 ( 95%)]  Loss: 1.173 (1.12)  Time: 0.255s,   15.71/s  (0.267s,   14.96/s)  LR: 1.673e-02  Data: 0.003 (0.005)\n",
      "Train: 1 [9100/9556 ( 95%)]  Loss: 1.372 (1.12)  Time: 0.266s,   15.02/s  (0.267s,   14.96/s)  LR: 1.673e-02  Data: 0.004 (0.005)\n",
      "Train: 1 [9150/9556 ( 96%)]  Loss: 0.9636 (1.12)  Time: 0.253s,   15.80/s  (0.267s,   14.96/s)  LR: 1.673e-02  Data: 0.002 (0.005)\n",
      "Train: 1 [9200/9556 ( 96%)]  Loss: 1.279 (1.12)  Time: 0.287s,   13.92/s  (0.267s,   14.97/s)  LR: 1.673e-02  Data: 0.005 (0.005)\n",
      "Train: 1 [9250/9556 ( 97%)]  Loss: 1.638 (1.12)  Time: 0.254s,   15.78/s  (0.267s,   14.97/s)  LR: 1.673e-02  Data: 0.003 (0.005)\n",
      "Train: 1 [9300/9556 ( 97%)]  Loss: 1.290 (1.12)  Time: 0.256s,   15.64/s  (0.267s,   14.97/s)  LR: 1.673e-02  Data: 0.002 (0.005)\n",
      "Train: 1 [9350/9556 ( 98%)]  Loss: 0.8917 (1.12)  Time: 0.252s,   15.88/s  (0.267s,   14.97/s)  LR: 1.673e-02  Data: 0.002 (0.005)\n",
      "Train: 1 [9400/9556 ( 98%)]  Loss: 1.401 (1.12)  Time: 0.276s,   14.47/s  (0.267s,   14.97/s)  LR: 1.673e-02  Data: 0.003 (0.005)\n",
      "Train: 1 [9450/9556 ( 99%)]  Loss: 1.025 (1.12)  Time: 0.254s,   15.74/s  (0.267s,   14.98/s)  LR: 1.673e-02  Data: 0.002 (0.005)\n",
      "Train: 1 [9500/9556 ( 99%)]  Loss: 0.8303 (1.12)  Time: 0.254s,   15.76/s  (0.267s,   14.98/s)  LR: 1.673e-02  Data: 0.002 (0.005)\n",
      "Train: 1 [9550/9556 (100%)]  Loss: 1.087 (1.11)  Time: 0.274s,   14.62/s  (0.267s,   14.98/s)  LR: 1.673e-02  Data: 0.001 (0.005)\n",
      "Train: 1 [9555/9556 (100%)]  Loss: 1.100 (1.11)  Time: 0.255s,   15.71/s  (0.267s,   14.98/s)  LR: 1.673e-02  Data: 0.000 (0.005)\n",
      "Test: [   0/2145]  Time: 0.322 (0.322)  Loss:  0.4878 (0.4878)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [  50/2145]  Time: 0.062 (0.067)  Loss:  0.4814 (0.4937)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 100/2145]  Time: 0.103 (0.063)  Loss:  0.5181 (0.5003)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 150/2145]  Time: 0.060 (0.062)  Loss:  0.4907 (0.4936)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 200/2145]  Time: 0.057 (0.061)  Loss:  0.4819 (0.4938)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 250/2145]  Time: 0.095 (0.061)  Loss:  0.4951 (0.4940)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 300/2145]  Time: 0.057 (0.061)  Loss:  0.4883 (0.4942)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 350/2145]  Time: 0.057 (0.061)  Loss:  0.4668 (0.4936)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 400/2145]  Time: 0.057 (0.060)  Loss:  0.5166 (0.4952)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 450/2145]  Time: 0.058 (0.060)  Loss:  0.4797 (0.4946)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 500/2145]  Time: 0.100 (0.060)  Loss:  0.4849 (0.4948)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 550/2145]  Time: 0.057 (0.060)  Loss:  0.4819 (0.4939)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 600/2145]  Time: 0.059 (0.061)  Loss:  0.4851 (0.4935)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 650/2145]  Time: 0.058 (0.061)  Loss:  0.4910 (0.4933)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 700/2145]  Time: 0.090 (0.061)  Loss:  0.4941 (0.4932)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 750/2145]  Time: 0.057 (0.061)  Loss:  0.5029 (0.4935)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 800/2145]  Time: 0.057 (0.061)  Loss:  0.4800 (0.4937)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 850/2145]  Time: 0.057 (0.061)  Loss:  0.4976 (0.4938)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 900/2145]  Time: 0.058 (0.061)  Loss:  0.4949 (0.4938)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [ 950/2145]  Time: 0.058 (0.061)  Loss:  0.5293 (0.4938)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1000/2145]  Time: 0.060 (0.061)  Loss:  0.4741 (0.4935)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1050/2145]  Time: 0.058 (0.061)  Loss:  0.4832 (0.4935)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1100/2145]  Time: 0.058 (0.061)  Loss:  0.5161 (0.4937)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1150/2145]  Time: 0.058 (0.061)  Loss:  0.4814 (0.4942)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1200/2145]  Time: 0.062 (0.061)  Loss:  0.5117 (0.4945)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1250/2145]  Time: 0.060 (0.061)  Loss:  1.8828 (0.5090)  Acc@1:  0.0000 (98.9608)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1300/2145]  Time: 0.057 (0.061)  Loss:  1.9131 (0.5598)  Acc@1:  0.0000 (95.1576)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1350/2145]  Time: 0.058 (0.061)  Loss:  1.6953 (0.6075)  Acc@1:  0.0000 (91.6358)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1400/2145]  Time: 0.066 (0.061)  Loss:  1.9199 (0.6510)  Acc@1:  0.0000 (88.3655)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1450/2145]  Time: 0.056 (0.061)  Loss:  1.9775 (0.6930)  Acc@1:  0.0000 (85.3205)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1500/2145]  Time: 0.082 (0.061)  Loss:  1.6162 (0.7264)  Acc@1:  0.0000 (82.4783)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1550/2145]  Time: 0.057 (0.061)  Loss:  1.5684 (0.7542)  Acc@1:  0.0000 (79.8195)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1600/2145]  Time: 0.058 (0.061)  Loss:  1.6289 (0.7801)  Acc@1:  0.0000 (77.3267)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1650/2145]  Time: 0.062 (0.061)  Loss:  1.5508 (0.8050)  Acc@1:  0.0000 (74.9849)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1700/2145]  Time: 0.057 (0.061)  Loss:  1.5820 (0.8286)  Acc@1:  0.0000 (72.7807)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1750/2145]  Time: 0.061 (0.061)  Loss:  1.5332 (0.8506)  Acc@1:  0.0000 (70.7025)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1800/2145]  Time: 0.065 (0.061)  Loss:  1.5176 (0.8710)  Acc@1:  0.0000 (68.7396)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1850/2145]  Time: 0.058 (0.061)  Loss:  1.6152 (0.8912)  Acc@1:  0.0000 (66.8828)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1900/2145]  Time: 0.058 (0.061)  Loss:  1.5361 (0.9101)  Acc@1:  0.0000 (65.1236)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [1950/2145]  Time: 0.058 (0.061)  Loss:  1.6523 (0.9277)  Acc@1:  0.0000 (63.4546)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [2000/2145]  Time: 0.094 (0.061)  Loss:  1.5723 (0.9442)  Acc@1:  0.0000 (61.8691)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [2050/2145]  Time: 0.057 (0.061)  Loss:  1.6084 (0.9604)  Acc@1:  0.0000 (60.3608)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [2100/2145]  Time: 0.057 (0.061)  Loss:  1.6299 (0.9766)  Acc@1:  0.0000 (58.9243)  Acc@5: 100.0000 (100.0000)\n",
      "Test: [2145/2145]  Time: 0.046 (0.061)  Loss:  2.9102 (1.0130)  Acc@1:  0.0000 (57.6954)  Acc@5: 100.0000 (100.0000)\n",
      "Current checkpoints:\n",
      " ('./output/train\\\\dfl-benchmark-training-fix-extract-images\\\\checkpoint-1.pth.tar', 57.6954444832809)\n",
      " ('./output/train\\\\dfl-benchmark-training-fix-extract-images\\\\checkpoint-0.pth.tar', 53.73412559711057)\n",
      "\n",
      "Train: 2 [   0/9556 (  0%)]  Loss: 1.239 (1.24)  Time: 0.529s,    7.56/s  (0.529s,    7.56/s)  LR: 3.337e-02  Data: 0.250 (0.250)\n",
      "Train: 2 [  50/9556 (  1%)]  Loss: 1.464 (1.01)  Time: 0.255s,   15.70/s  (0.269s,   14.85/s)  LR: 3.337e-02  Data: 0.002 (0.008)\n",
      "*** Best metric: 57.6954444832809 (epoch 1)\n"
     ]
    }
   ],
   "source": [
    "%run /git_workspace/PML_project/PMLDL-project/image_models/train.py /git_workspace/PML_project/PMLDL-project/work/split_images/ \\\n",
    "    -b 4 \\\n",
    "    --amp \\\n",
    "    --epochs 20 \\\n",
    "    --pretrained \\\n",
    "    --num-classes 4 \\\n",
    "    --model tf_efficientnet_b5_ap \\\n",
    "    --experiment dfl-benchmark-training-fix-extract-images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026f9de-4aba-45d3-973f-51ec30e2a096",
   "metadata": {},
   "source": [
    "We take the training checkpoints and average the weights from the last few ones using the script provided by timm to save it as a model so we don't have to train it every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa49dcad-1806-4c3a-bdef-6d392221e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('/git_workspace/PML_project/PMLDL-project/model/tf_efficientnet_b5_ap-456-fix.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbc0ee3a-4d27-4bc7-981a-ddbdd9b10ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Extracting metric from checkpoint '/git_workspace/PML_project/PMLDL-project/notebooks/output/train/dfl-benchmark-training-fix-extract-images\\checkpoint-0.pth.tar'\n",
      "=> Extracting metric from checkpoint '/git_workspace/PML_project/PMLDL-project/notebooks/output/train/dfl-benchmark-training-fix-extract-images\\checkpoint-1.pth.tar'\n",
      "=> Extracting metric from checkpoint '/git_workspace/PML_project/PMLDL-project/notebooks/output/train/dfl-benchmark-training-fix-extract-images\\last.pth.tar'\n",
      "=> Extracting metric from checkpoint '/git_workspace/PML_project/PMLDL-project/notebooks/output/train/dfl-benchmark-training-fix-extract-images\\model_best.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded state_dict from checkpoint '/git_workspace/PML_project/PMLDL-project/notebooks/output/train/dfl-benchmark-training-fix-extract-images\\checkpoint-0.pth.tar'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected checkpoints:\n",
      "53.73412559711057 /git_workspace/PML_project/PMLDL-project/notebooks/output/train/dfl-benchmark-training-fix-extract-images\\checkpoint-0.pth.tar\n",
      "57.6954444832809 /git_workspace/PML_project/PMLDL-project/notebooks/output/train/dfl-benchmark-training-fix-extract-images\\checkpoint-1.pth.tar\n",
      "57.6954444832809 /git_workspace/PML_project/PMLDL-project/notebooks/output/train/dfl-benchmark-training-fix-extract-images\\last.pth.tar\n",
      "57.6954444832809 /git_workspace/PML_project/PMLDL-project/notebooks/output/train/dfl-benchmark-training-fix-extract-images\\model_best.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded state_dict from checkpoint '/git_workspace/PML_project/PMLDL-project/notebooks/output/train/dfl-benchmark-training-fix-extract-images\\checkpoint-1.pth.tar'\n",
      "Loaded state_dict from checkpoint '/git_workspace/PML_project/PMLDL-project/notebooks/output/train/dfl-benchmark-training-fix-extract-images\\last.pth.tar'\n",
      "Loaded state_dict from checkpoint '/git_workspace/PML_project/PMLDL-project/notebooks/output/train/dfl-benchmark-training-fix-extract-images\\model_best.pth.tar'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saved state_dict to '/git_workspace/PML_project/PMLDL-project/model/tf_efficientnet_b5_ap-456-fix.pt, SHA256: 26224193caa196fd45979e16a519af99220119cfa11cfe3b5e9df76e2fd93eda'\n"
     ]
    }
   ],
   "source": [
    "%run /git_workspace/PML_project/PMLDL-project/image_models/avg_checkpoints.py --input /git_workspace/PML_project/PMLDL-project/notebooks/output/train/dfl-benchmark-training-fix-extract-images \\\n",
    "    --output /git_workspace/PML_project/PMLDL-project/model/tf_efficientnet_b5_ap-456-fix.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042bf425-6918-4cfd-a57d-821b53ffc019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
